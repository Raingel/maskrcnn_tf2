{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaskRCNN training. Balloon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import tensorflow as tf\n",
    "\n",
    "from samples.balloon import balloon\n",
    "from preprocess import preprocess\n",
    "from preprocess import augmentation as aug\n",
    "from training import train_model\n",
    "from model import mask_rcnn_functional\n",
    "from common.utils import tf_limit_gpu_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-06-24T01:28:19.527328+03:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.7\n",
      "IPython version      : 7.16.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-65-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "tensorflow: 2.2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs Memory limit: 4500\n",
      "Physical GPU-devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "tf_limit_gpu_memory(tf, 4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.config import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_shape': (512, 512, 3),\n",
       " 'img_size': 512,\n",
       " 'backbone': 'mobilenet',\n",
       " 'meta_shape': 14,\n",
       " 'num_classes': 2,\n",
       " 'class_dict': {'balloon': 1, 'background': 0},\n",
       " 'normalization': None,\n",
       " 'image_min_dim': 300,\n",
       " 'image_min_scale': 0,\n",
       " 'image_max_dim': 512,\n",
       " 'image_resize_mode': 'square',\n",
       " 'use_mini_masks': False,\n",
       " 'mini_mask_shape': (32, 32),\n",
       " 'mask_shape': (28, 28),\n",
       " 'epochs': 30,\n",
       " 'gpu_num': 1,\n",
       " 'batch_size': 1,\n",
       " 'images_per_gpu': 1,\n",
       " 'training': True,\n",
       " 'log_per_steps': 5,\n",
       " 'use_multiprocessing': True,\n",
       " 'workers': 6,\n",
       " 'callback': {'log_dir': 'logs/scalars',\n",
       "  'reduce_lr_on_plateau': 0.98,\n",
       "  'reduce_lr_on_plateau_patience': 10,\n",
       "  'save_weights_only': True,\n",
       "  'save_best_only': True,\n",
       "  'histogram_freq': 0,\n",
       "  'profile_batch': '1,2'},\n",
       " 'backbone_strides': [4, 8, 16, 32, 64],\n",
       " 'top_down_pyramid_size': 256,\n",
       " 'rpn_anchor_scales': (32, 64, 128, 256, 512),\n",
       " 'rpn_anchor_ratios': [0.5, 1, 2],\n",
       " 'rpn_anchor_stride': 1,\n",
       " 'rpn_train_anchors_per_image': 256,\n",
       " 'max_gt_instances': 100,\n",
       " 'rpn_bbox_std_dev': array([0.1, 0.1, 0.2, 0.2], dtype=float32),\n",
       " 'bbox_std_dev': array([0.1, 0.1, 0.2, 0.2], dtype=float32),\n",
       " 'rpn_nms_threshold': 0.7,\n",
       " 'use_rpn_rois': True,\n",
       " 'random_rois': 0,\n",
       " 'detection_min_confidence': 0.7,\n",
       " 'detection_nms_threshold': 0.3,\n",
       " 'detection_max_instances': 100,\n",
       " 'pre_nms_limit': 6000,\n",
       " 'post_nms_rois_training': 2000,\n",
       " 'post_nms_rois_inference': 1000,\n",
       " 'train_rois_per_image': 200,\n",
       " 'roi_positive_ratio': 0.33,\n",
       " 'pool_size': 7,\n",
       " 'mask_pool_size': 14,\n",
       " 'fpn_cls_fc_layers_size': 1024,\n",
       " 'loss_weights': [1, 1, 1, 1, 1],\n",
       " 'optimizer_kwargs': {'learning_rate': 0.001,\n",
       "  'clipvalue': 5.0,\n",
       "  'name': 'adamax'},\n",
       " 'weight_decay': 0.0002,\n",
       " 'train_bn': False,\n",
       " 'l2_reg_batchnorm': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG.update({'class_dict': {'balloon': 1, 'background': 0},\n",
    "               'num_classes': 2,\n",
    "               'epochs': 30,\n",
    "              },\n",
    "             )\n",
    "CONFIG.update({'meta_shape': (1 + 3 + 3 + 4 + 1 + CONFIG['num_classes']),})\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] Training mode\n",
      "WARNING:tensorflow:Layer norm_boxes_anchors is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[MaskRCNN] Backbone architecture: mobilenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/envs/tf_env/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "model = mask_rcnn_functional(config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mobilenet'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['backbone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found annotation file: via_region_data.json in dataset path: /home/alexander/Documents/py_projects/bitbucket/mask-rcnn/balloon/train\n",
      "Found annotation file: via_region_data.json in dataset path: /home/alexander/Documents/py_projects/bitbucket/mask-rcnn/balloon/val\n"
     ]
    }
   ],
   "source": [
    "base_dir = os.getcwd().replace('src', 'balloon')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "\n",
    "train_dataset = balloon.BalloonDataset(images_dir=train_dir,\n",
    "                                       class_key='object',\n",
    "                                       classes_dict=CONFIG['class_dict'],\n",
    "                                       augmentation=aug.get_training_augmentation(\n",
    "                                           image_size=CONFIG['img_size'],\n",
    "                                           normalize=CONFIG['normalization']\n",
    "                                       ),\n",
    "                                       json_annotation_key=None,\n",
    "                                       **CONFIG\n",
    "                                            )\n",
    "\n",
    "val_dataset = balloon.BalloonDataset(images_dir=val_dir,\n",
    "                                     class_key='object',\n",
    "                                     classes_dict=CONFIG['class_dict'],\n",
    "                                     augmentation=aug.get_validation_augmentation(\n",
    "                                         image_size=CONFIG['img_size'],\n",
    "                                         normalize=CONFIG['normalization']\n",
    "                                     ),\n",
    "                                     json_annotation_key=None,\n",
    "                                     **CONFIG\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train DataLoader. Steps per epoch: 61\n",
      "val DataLoader. Steps per epoch: 13\n",
      "MaskRCNN Losses:\n",
      "rpn_class_loss: <layers.losses.RPNClassLoss object at 0x7fcda01eddd0>\n",
      "rpn_bbox_loss: <layers.losses.RPNBboxLoss object at 0x7fcda051d190>\n",
      "mrcnn_class_loss: <layers.losses.MRCNNClassLoss object at 0x7fcda01ede50>\n",
      "mrcnn_bbox_loss: <layers.losses.MRCNNBboxLoss object at 0x7fcda07aa7d0>\n",
      "mrcnn_mask_loss: <layers.losses.MRCNNMaskLoss object at 0x7fcda01edd90>\n",
      "l2_regularizer: <layers.losses.L2RegLoss object at 0x7fcda0626950>\n",
      "\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:From /home/alexander/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:644: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.3147 - rpn_bbox_loss: 4.5930 - mrcnn_class_loss: 1.4794 - mrcnn_bbox_loss: 10.7980 - mrcnn_mask_loss: 0.6947 - l2_regularizer: 0.0084 - loss_sum: 17.8882\n",
      "Epoch 00001: val_loss_sum improved from inf to 8.33637, saving model to logs/scalars/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0001.ckpt\n",
      "61/61 [==============================] - 61s 1s/step - rpn_class_loss: 0.3147 - rpn_bbox_loss: 4.5930 - mrcnn_class_loss: 1.4794 - mrcnn_bbox_loss: 10.7980 - mrcnn_mask_loss: 0.6947 - l2_regularizer: 0.0084 - loss_sum: 17.8882 - val_rpn_class_loss: 0.1362 - val_rpn_bbox_loss: 0.9011 - val_mrcnn_class_loss: 0.5164 - val_mrcnn_bbox_loss: 6.1009 - val_mrcnn_mask_loss: 0.6817 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 8.3364 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0702 - rpn_bbox_loss: 0.9416 - mrcnn_class_loss: 0.0985 - mrcnn_bbox_loss: 1.1810 - mrcnn_mask_loss: 0.5495 - l2_regularizer: 0.0084 - loss_sum: 2.8491\n",
      "Epoch 00002: val_loss_sum improved from 8.33637 to 2.20023, saving model to logs/scalars/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0002.ckpt\n",
      "61/61 [==============================] - 64s 1s/step - rpn_class_loss: 0.0702 - rpn_bbox_loss: 0.9416 - mrcnn_class_loss: 0.0985 - mrcnn_bbox_loss: 1.1810 - mrcnn_mask_loss: 0.5495 - l2_regularizer: 0.0084 - loss_sum: 2.8491 - val_rpn_class_loss: 0.0612 - val_rpn_bbox_loss: 0.7674 - val_mrcnn_class_loss: 0.0411 - val_mrcnn_bbox_loss: 0.7285 - val_mrcnn_mask_loss: 0.6021 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 2.2002 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0679 - rpn_bbox_loss: 0.5647 - mrcnn_class_loss: 0.0503 - mrcnn_bbox_loss: 0.6538 - mrcnn_mask_loss: 0.5913 - l2_regularizer: 0.0083 - loss_sum: 1.9364\n",
      "Epoch 00003: val_loss_sum improved from 2.20023 to 1.71945, saving model to logs/scalars/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0003.ckpt\n",
      "61/61 [==============================] - 66s 1s/step - rpn_class_loss: 0.0679 - rpn_bbox_loss: 0.5647 - mrcnn_class_loss: 0.0503 - mrcnn_bbox_loss: 0.6538 - mrcnn_mask_loss: 0.5913 - l2_regularizer: 0.0083 - loss_sum: 1.9364 - val_rpn_class_loss: 0.0576 - val_rpn_bbox_loss: 0.4610 - val_mrcnn_class_loss: 0.0703 - val_mrcnn_bbox_loss: 0.6020 - val_mrcnn_mask_loss: 0.5286 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.7194 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0484 - rpn_bbox_loss: 0.4294 - mrcnn_class_loss: 0.0561 - mrcnn_bbox_loss: 0.6683 - mrcnn_mask_loss: 0.6017 - l2_regularizer: 0.0083 - loss_sum: 1.8123\n",
      "Epoch 00004: val_loss_sum did not improve from 1.71945\n",
      "61/61 [==============================] - 68s 1s/step - rpn_class_loss: 0.0484 - rpn_bbox_loss: 0.4294 - mrcnn_class_loss: 0.0561 - mrcnn_bbox_loss: 0.6683 - mrcnn_mask_loss: 0.6017 - l2_regularizer: 0.0083 - loss_sum: 1.8123 - val_rpn_class_loss: 0.0626 - val_rpn_bbox_loss: 0.5649 - val_mrcnn_class_loss: 0.0439 - val_mrcnn_bbox_loss: 0.6136 - val_mrcnn_mask_loss: 0.5594 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.8444 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0510 - rpn_bbox_loss: 0.5079 - mrcnn_class_loss: 0.0398 - mrcnn_bbox_loss: 0.6172 - mrcnn_mask_loss: 0.5803 - l2_regularizer: 0.0083 - loss_sum: 1.8046\n",
      "Epoch 00005: val_loss_sum did not improve from 1.71945\n",
      "61/61 [==============================] - 67s 1s/step - rpn_class_loss: 0.0510 - rpn_bbox_loss: 0.5079 - mrcnn_class_loss: 0.0398 - mrcnn_bbox_loss: 0.6172 - mrcnn_mask_loss: 0.5803 - l2_regularizer: 0.0083 - loss_sum: 1.8046 - val_rpn_class_loss: 0.0577 - val_rpn_bbox_loss: 0.5498 - val_mrcnn_class_loss: 0.0302 - val_mrcnn_bbox_loss: 0.6014 - val_mrcnn_mask_loss: 0.5251 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.7643 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0555 - rpn_bbox_loss: 0.5012 - mrcnn_class_loss: 0.0383 - mrcnn_bbox_loss: 0.5653 - mrcnn_mask_loss: 0.5555 - l2_regularizer: 0.0083 - loss_sum: 1.7241\n",
      "Epoch 00006: val_loss_sum did not improve from 1.71945\n",
      "61/61 [==============================] - 66s 1s/step - rpn_class_loss: 0.0555 - rpn_bbox_loss: 0.5012 - mrcnn_class_loss: 0.0383 - mrcnn_bbox_loss: 0.5653 - mrcnn_mask_loss: 0.5555 - l2_regularizer: 0.0083 - loss_sum: 1.7241 - val_rpn_class_loss: 0.0608 - val_rpn_bbox_loss: 0.4651 - val_mrcnn_class_loss: 0.0548 - val_mrcnn_bbox_loss: 0.6233 - val_mrcnn_mask_loss: 0.5952 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.7992 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0444 - rpn_bbox_loss: 0.4750 - mrcnn_class_loss: 0.0477 - mrcnn_bbox_loss: 0.6044 - mrcnn_mask_loss: 0.5890 - l2_regularizer: 0.0083 - loss_sum: 1.7689\n",
      "Epoch 00007: val_loss_sum did not improve from 1.71945\n",
      "61/61 [==============================] - 67s 1s/step - rpn_class_loss: 0.0444 - rpn_bbox_loss: 0.4750 - mrcnn_class_loss: 0.0477 - mrcnn_bbox_loss: 0.6044 - mrcnn_mask_loss: 0.5890 - l2_regularizer: 0.0083 - loss_sum: 1.7689 - val_rpn_class_loss: 0.0533 - val_rpn_bbox_loss: 0.4937 - val_mrcnn_class_loss: 0.0459 - val_mrcnn_bbox_loss: 0.6302 - val_mrcnn_mask_loss: 0.6486 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.8718 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0439 - rpn_bbox_loss: 0.4378 - mrcnn_class_loss: 0.0569 - mrcnn_bbox_loss: 0.6356 - mrcnn_mask_loss: 0.5629 - l2_regularizer: 0.0083 - loss_sum: 1.7453\n",
      "Epoch 00008: val_loss_sum improved from 1.71945 to 1.57367, saving model to logs/scalars/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0008.ckpt\n",
      "61/61 [==============================] - 68s 1s/step - rpn_class_loss: 0.0439 - rpn_bbox_loss: 0.4378 - mrcnn_class_loss: 0.0569 - mrcnn_bbox_loss: 0.6356 - mrcnn_mask_loss: 0.5629 - l2_regularizer: 0.0083 - loss_sum: 1.7453 - val_rpn_class_loss: 0.0666 - val_rpn_bbox_loss: 0.4773 - val_mrcnn_class_loss: 0.0351 - val_mrcnn_bbox_loss: 0.4831 - val_mrcnn_mask_loss: 0.5115 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.5737 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0456 - rpn_bbox_loss: 0.4790 - mrcnn_class_loss: 0.0414 - mrcnn_bbox_loss: 0.5594 - mrcnn_mask_loss: 0.5464 - l2_regularizer: 0.0083 - loss_sum: 1.6801\n",
      "Epoch 00009: val_loss_sum did not improve from 1.57367\n",
      "61/61 [==============================] - 67s 1s/step - rpn_class_loss: 0.0456 - rpn_bbox_loss: 0.4790 - mrcnn_class_loss: 0.0414 - mrcnn_bbox_loss: 0.5594 - mrcnn_mask_loss: 0.5464 - l2_regularizer: 0.0083 - loss_sum: 1.6801 - val_rpn_class_loss: 0.0529 - val_rpn_bbox_loss: 0.3780 - val_mrcnn_class_loss: 0.0444 - val_mrcnn_bbox_loss: 0.7085 - val_mrcnn_mask_loss: 0.5598 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.7436 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0441 - rpn_bbox_loss: 0.4548 - mrcnn_class_loss: 0.0525 - mrcnn_bbox_loss: 0.5279 - mrcnn_mask_loss: 0.5277 - l2_regularizer: 0.0083 - loss_sum: 1.6154\n",
      "Epoch 00010: val_loss_sum improved from 1.57367 to 1.53026, saving model to logs/scalars/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0010.ckpt\n",
      "61/61 [==============================] - 69s 1s/step - rpn_class_loss: 0.0441 - rpn_bbox_loss: 0.4548 - mrcnn_class_loss: 0.0525 - mrcnn_bbox_loss: 0.5279 - mrcnn_mask_loss: 0.5277 - l2_regularizer: 0.0083 - loss_sum: 1.6154 - val_rpn_class_loss: 0.0580 - val_rpn_bbox_loss: 0.4889 - val_mrcnn_class_loss: 0.0264 - val_mrcnn_bbox_loss: 0.4822 - val_mrcnn_mask_loss: 0.4748 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.5303 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0489 - rpn_bbox_loss: 0.4832 - mrcnn_class_loss: 0.0409 - mrcnn_bbox_loss: 0.5577 - mrcnn_mask_loss: 0.5382 - l2_regularizer: 0.0083 - loss_sum: 1.6774\n",
      "Epoch 00011: val_loss_sum did not improve from 1.53026\n",
      "61/61 [==============================] - 69s 1s/step - rpn_class_loss: 0.0489 - rpn_bbox_loss: 0.4832 - mrcnn_class_loss: 0.0409 - mrcnn_bbox_loss: 0.5577 - mrcnn_mask_loss: 0.5382 - l2_regularizer: 0.0083 - loss_sum: 1.6774 - val_rpn_class_loss: 0.0429 - val_rpn_bbox_loss: 0.5115 - val_mrcnn_class_loss: 0.0480 - val_mrcnn_bbox_loss: 0.5725 - val_mrcnn_mask_loss: 0.4749 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.6497 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0628 - rpn_bbox_loss: 0.4994 - mrcnn_class_loss: 0.0410 - mrcnn_bbox_loss: 0.5305 - mrcnn_mask_loss: 0.4771 - l2_regularizer: 0.0083 - loss_sum: 1.6191\n",
      "Epoch 00012: val_loss_sum improved from 1.53026 to 1.39191, saving model to logs/scalars/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0012.ckpt\n",
      "61/61 [==============================] - 70s 1s/step - rpn_class_loss: 0.0628 - rpn_bbox_loss: 0.4994 - mrcnn_class_loss: 0.0410 - mrcnn_bbox_loss: 0.5305 - mrcnn_mask_loss: 0.4771 - l2_regularizer: 0.0083 - loss_sum: 1.6191 - val_rpn_class_loss: 0.0410 - val_rpn_bbox_loss: 0.4043 - val_mrcnn_class_loss: 0.0292 - val_mrcnn_bbox_loss: 0.5091 - val_mrcnn_mask_loss: 0.4082 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.3919 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0564 - rpn_bbox_loss: 0.4559 - mrcnn_class_loss: 0.0427 - mrcnn_bbox_loss: 0.4613 - mrcnn_mask_loss: 0.4654 - l2_regularizer: 0.0083 - loss_sum: 1.4900\n",
      "Epoch 00013: val_loss_sum did not improve from 1.39191\n",
      "61/61 [==============================] - 68s 1s/step - rpn_class_loss: 0.0564 - rpn_bbox_loss: 0.4559 - mrcnn_class_loss: 0.0427 - mrcnn_bbox_loss: 0.4613 - mrcnn_mask_loss: 0.4654 - l2_regularizer: 0.0083 - loss_sum: 1.4900 - val_rpn_class_loss: 0.0517 - val_rpn_bbox_loss: 0.4969 - val_mrcnn_class_loss: 0.0315 - val_mrcnn_bbox_loss: 0.4593 - val_mrcnn_mask_loss: 0.4255 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.4648 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0670 - rpn_bbox_loss: 0.5387 - mrcnn_class_loss: 0.0391 - mrcnn_bbox_loss: 0.4994 - mrcnn_mask_loss: 0.4182 - l2_regularizer: 0.0083 - loss_sum: 1.5707\n",
      "Epoch 00014: val_loss_sum did not improve from 1.39191\n",
      "61/61 [==============================] - 68s 1s/step - rpn_class_loss: 0.0670 - rpn_bbox_loss: 0.5387 - mrcnn_class_loss: 0.0391 - mrcnn_bbox_loss: 0.4994 - mrcnn_mask_loss: 0.4182 - l2_regularizer: 0.0083 - loss_sum: 1.5707 - val_rpn_class_loss: 0.0475 - val_rpn_bbox_loss: 0.5365 - val_mrcnn_class_loss: 0.0332 - val_mrcnn_bbox_loss: 0.5872 - val_mrcnn_mask_loss: 0.4578 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.6621 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0461 - rpn_bbox_loss: 0.4583 - mrcnn_class_loss: 0.0403 - mrcnn_bbox_loss: 0.4938 - mrcnn_mask_loss: 0.4439 - l2_regularizer: 0.0083 - loss_sum: 1.4909\n",
      "Epoch 00015: val_loss_sum did not improve from 1.39191\n",
      "61/61 [==============================] - 69s 1s/step - rpn_class_loss: 0.0461 - rpn_bbox_loss: 0.4583 - mrcnn_class_loss: 0.0403 - mrcnn_bbox_loss: 0.4938 - mrcnn_mask_loss: 0.4439 - l2_regularizer: 0.0083 - loss_sum: 1.4909 - val_rpn_class_loss: 0.0464 - val_rpn_bbox_loss: 0.3926 - val_mrcnn_class_loss: 0.0564 - val_mrcnn_bbox_loss: 0.4435 - val_mrcnn_mask_loss: 0.4988 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.4378 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0491 - rpn_bbox_loss: 0.4425 - mrcnn_class_loss: 0.0401 - mrcnn_bbox_loss: 0.4500 - mrcnn_mask_loss: 0.3735 - l2_regularizer: 0.0083 - loss_sum: 1.3636\n",
      "Epoch 00016: val_loss_sum improved from 1.39191 to 1.22282, saving model to logs/scalars/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0016.ckpt\n",
      "61/61 [==============================] - 67s 1s/step - rpn_class_loss: 0.0491 - rpn_bbox_loss: 0.4425 - mrcnn_class_loss: 0.0401 - mrcnn_bbox_loss: 0.4500 - mrcnn_mask_loss: 0.3735 - l2_regularizer: 0.0083 - loss_sum: 1.3636 - val_rpn_class_loss: 0.0402 - val_rpn_bbox_loss: 0.4703 - val_mrcnn_class_loss: 0.0303 - val_mrcnn_bbox_loss: 0.3837 - val_mrcnn_mask_loss: 0.2983 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.2228 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0440 - rpn_bbox_loss: 0.4390 - mrcnn_class_loss: 0.0420 - mrcnn_bbox_loss: 0.4588 - mrcnn_mask_loss: 0.3987 - l2_regularizer: 0.0083 - loss_sum: 1.3908\n",
      "Epoch 00017: val_loss_sum did not improve from 1.22282\n",
      "61/61 [==============================] - 66s 1s/step - rpn_class_loss: 0.0440 - rpn_bbox_loss: 0.4390 - mrcnn_class_loss: 0.0420 - mrcnn_bbox_loss: 0.4588 - mrcnn_mask_loss: 0.3987 - l2_regularizer: 0.0083 - loss_sum: 1.3908 - val_rpn_class_loss: 0.0411 - val_rpn_bbox_loss: 0.4477 - val_mrcnn_class_loss: 0.0555 - val_mrcnn_bbox_loss: 0.4660 - val_mrcnn_mask_loss: 0.4204 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.4306 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0612 - rpn_bbox_loss: 0.5566 - mrcnn_class_loss: 0.0421 - mrcnn_bbox_loss: 0.4337 - mrcnn_mask_loss: 0.4044 - l2_regularizer: 0.0083 - loss_sum: 1.5064\n",
      "Epoch 00018: val_loss_sum did not improve from 1.22282\n",
      "61/61 [==============================] - 68s 1s/step - rpn_class_loss: 0.0612 - rpn_bbox_loss: 0.5566 - mrcnn_class_loss: 0.0421 - mrcnn_bbox_loss: 0.4337 - mrcnn_mask_loss: 0.4044 - l2_regularizer: 0.0083 - loss_sum: 1.5064 - val_rpn_class_loss: 0.0474 - val_rpn_bbox_loss: 0.4695 - val_mrcnn_class_loss: 0.0435 - val_mrcnn_bbox_loss: 0.5533 - val_mrcnn_mask_loss: 0.3655 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.4792 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0449 - rpn_bbox_loss: 0.4512 - mrcnn_class_loss: 0.0518 - mrcnn_bbox_loss: 0.5631 - mrcnn_mask_loss: 0.4575 - l2_regularizer: 0.0083 - loss_sum: 1.5768\n",
      "Epoch 00019: val_loss_sum did not improve from 1.22282\n",
      "61/61 [==============================] - 68s 1s/step - rpn_class_loss: 0.0449 - rpn_bbox_loss: 0.4512 - mrcnn_class_loss: 0.0518 - mrcnn_bbox_loss: 0.5631 - mrcnn_mask_loss: 0.4575 - l2_regularizer: 0.0083 - loss_sum: 1.5768 - val_rpn_class_loss: 0.0321 - val_rpn_bbox_loss: 0.4417 - val_mrcnn_class_loss: 0.0443 - val_mrcnn_bbox_loss: 0.4808 - val_mrcnn_mask_loss: 0.3733 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.3722 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0387 - rpn_bbox_loss: 0.4858 - mrcnn_class_loss: 0.0443 - mrcnn_bbox_loss: 0.4948 - mrcnn_mask_loss: 0.3870 - l2_regularizer: 0.0083 - loss_sum: 1.4588\n",
      "Epoch 00020: val_loss_sum did not improve from 1.22282\n",
      "61/61 [==============================] - 66s 1s/step - rpn_class_loss: 0.0387 - rpn_bbox_loss: 0.4858 - mrcnn_class_loss: 0.0443 - mrcnn_bbox_loss: 0.4948 - mrcnn_mask_loss: 0.3870 - l2_regularizer: 0.0083 - loss_sum: 1.4588 - val_rpn_class_loss: 0.0582 - val_rpn_bbox_loss: 0.5107 - val_mrcnn_class_loss: 0.0570 - val_mrcnn_bbox_loss: 0.6031 - val_mrcnn_mask_loss: 0.5300 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.7590 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0399 - rpn_bbox_loss: 0.4265 - mrcnn_class_loss: 0.0419 - mrcnn_bbox_loss: 0.4628 - mrcnn_mask_loss: 0.3826 - l2_regularizer: 0.0083 - loss_sum: 1.3619\n",
      "Epoch 00021: val_loss_sum improved from 1.22282 to 1.20168, saving model to logs/scalars/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0021.ckpt\n",
      "61/61 [==============================] - 67s 1s/step - rpn_class_loss: 0.0399 - rpn_bbox_loss: 0.4265 - mrcnn_class_loss: 0.0419 - mrcnn_bbox_loss: 0.4628 - mrcnn_mask_loss: 0.3826 - l2_regularizer: 0.0083 - loss_sum: 1.3619 - val_rpn_class_loss: 0.0357 - val_rpn_bbox_loss: 0.3420 - val_mrcnn_class_loss: 0.0458 - val_mrcnn_bbox_loss: 0.4427 - val_mrcnn_mask_loss: 0.3354 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.2017 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0381 - rpn_bbox_loss: 0.4248 - mrcnn_class_loss: 0.0480 - mrcnn_bbox_loss: 0.4485 - mrcnn_mask_loss: 0.3516 - l2_regularizer: 0.0083 - loss_sum: 1.3194\n",
      "Epoch 00022: val_loss_sum did not improve from 1.20168\n",
      "61/61 [==============================] - 67s 1s/step - rpn_class_loss: 0.0381 - rpn_bbox_loss: 0.4248 - mrcnn_class_loss: 0.0480 - mrcnn_bbox_loss: 0.4485 - mrcnn_mask_loss: 0.3516 - l2_regularizer: 0.0083 - loss_sum: 1.3194 - val_rpn_class_loss: 0.0309 - val_rpn_bbox_loss: 0.4083 - val_mrcnn_class_loss: 0.0330 - val_mrcnn_bbox_loss: 0.4182 - val_mrcnn_mask_loss: 0.3592 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.2495 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0451 - rpn_bbox_loss: 0.5434 - mrcnn_class_loss: 0.0441 - mrcnn_bbox_loss: 0.4288 - mrcnn_mask_loss: 0.3523 - l2_regularizer: 0.0083 - loss_sum: 1.4220\n",
      "Epoch 00023: val_loss_sum improved from 1.20168 to 1.06905, saving model to logs/scalars/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0023.ckpt\n",
      "61/61 [==============================] - 67s 1s/step - rpn_class_loss: 0.0451 - rpn_bbox_loss: 0.5434 - mrcnn_class_loss: 0.0441 - mrcnn_bbox_loss: 0.4288 - mrcnn_mask_loss: 0.3523 - l2_regularizer: 0.0083 - loss_sum: 1.4220 - val_rpn_class_loss: 0.0333 - val_rpn_bbox_loss: 0.2813 - val_mrcnn_class_loss: 0.0652 - val_mrcnn_bbox_loss: 0.3511 - val_mrcnn_mask_loss: 0.3382 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.0690 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0402 - rpn_bbox_loss: 0.4965 - mrcnn_class_loss: 0.0526 - mrcnn_bbox_loss: 0.3926 - mrcnn_mask_loss: 0.3213 - l2_regularizer: 0.0083 - loss_sum: 1.3115\n",
      "Epoch 00024: val_loss_sum did not improve from 1.06905\n",
      "61/61 [==============================] - 66s 1s/step - rpn_class_loss: 0.0402 - rpn_bbox_loss: 0.4965 - mrcnn_class_loss: 0.0526 - mrcnn_bbox_loss: 0.3926 - mrcnn_mask_loss: 0.3213 - l2_regularizer: 0.0083 - loss_sum: 1.3115 - val_rpn_class_loss: 0.0375 - val_rpn_bbox_loss: 0.4466 - val_mrcnn_class_loss: 0.0442 - val_mrcnn_bbox_loss: 0.3896 - val_mrcnn_mask_loss: 0.2806 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.1984 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0324 - rpn_bbox_loss: 0.4287 - mrcnn_class_loss: 0.0461 - mrcnn_bbox_loss: 0.4140 - mrcnn_mask_loss: 0.3631 - l2_regularizer: 0.0083 - loss_sum: 1.2927\n",
      "Epoch 00025: val_loss_sum did not improve from 1.06905\n",
      "61/61 [==============================] - 66s 1s/step - rpn_class_loss: 0.0324 - rpn_bbox_loss: 0.4287 - mrcnn_class_loss: 0.0461 - mrcnn_bbox_loss: 0.4140 - mrcnn_mask_loss: 0.3631 - l2_regularizer: 0.0083 - loss_sum: 1.2927 - val_rpn_class_loss: 0.0401 - val_rpn_bbox_loss: 0.4746 - val_mrcnn_class_loss: 0.0475 - val_mrcnn_bbox_loss: 0.4516 - val_mrcnn_mask_loss: 0.3265 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.3403 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0352 - rpn_bbox_loss: 0.4596 - mrcnn_class_loss: 0.0374 - mrcnn_bbox_loss: 0.4012 - mrcnn_mask_loss: 0.2851 - l2_regularizer: 0.0083 - loss_sum: 1.2269\n",
      "Epoch 00026: val_loss_sum did not improve from 1.06905\n",
      "61/61 [==============================] - 66s 1s/step - rpn_class_loss: 0.0352 - rpn_bbox_loss: 0.4596 - mrcnn_class_loss: 0.0374 - mrcnn_bbox_loss: 0.4012 - mrcnn_mask_loss: 0.2851 - l2_regularizer: 0.0083 - loss_sum: 1.2269 - val_rpn_class_loss: 0.0369 - val_rpn_bbox_loss: 0.4568 - val_mrcnn_class_loss: 0.0495 - val_mrcnn_bbox_loss: 0.4090 - val_mrcnn_mask_loss: 0.2929 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.2452 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0423 - rpn_bbox_loss: 0.4741 - mrcnn_class_loss: 0.0437 - mrcnn_bbox_loss: 0.4127 - mrcnn_mask_loss: 0.3081 - l2_regularizer: 0.0083 - loss_sum: 1.2893\n",
      "Epoch 00027: val_loss_sum did not improve from 1.06905\n",
      "61/61 [==============================] - 67s 1s/step - rpn_class_loss: 0.0423 - rpn_bbox_loss: 0.4741 - mrcnn_class_loss: 0.0437 - mrcnn_bbox_loss: 0.4127 - mrcnn_mask_loss: 0.3081 - l2_regularizer: 0.0083 - loss_sum: 1.2893 - val_rpn_class_loss: 0.0433 - val_rpn_bbox_loss: 0.4497 - val_mrcnn_class_loss: 0.0385 - val_mrcnn_bbox_loss: 0.3967 - val_mrcnn_mask_loss: 0.3712 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.2994 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0364 - rpn_bbox_loss: 0.4499 - mrcnn_class_loss: 0.0438 - mrcnn_bbox_loss: 0.4403 - mrcnn_mask_loss: 0.3413 - l2_regularizer: 0.0083 - loss_sum: 1.3201\n",
      "Epoch 00028: val_loss_sum did not improve from 1.06905\n",
      "61/61 [==============================] - 68s 1s/step - rpn_class_loss: 0.0364 - rpn_bbox_loss: 0.4499 - mrcnn_class_loss: 0.0438 - mrcnn_bbox_loss: 0.4403 - mrcnn_mask_loss: 0.3413 - l2_regularizer: 0.0083 - loss_sum: 1.3201 - val_rpn_class_loss: 0.0493 - val_rpn_bbox_loss: 0.5457 - val_mrcnn_class_loss: 0.0308 - val_mrcnn_bbox_loss: 0.3180 - val_mrcnn_mask_loss: 0.3306 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.2745 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0403 - rpn_bbox_loss: 0.4665 - mrcnn_class_loss: 0.0560 - mrcnn_bbox_loss: 0.4596 - mrcnn_mask_loss: 0.3140 - l2_regularizer: 0.0083 - loss_sum: 1.3448\n",
      "Epoch 00029: val_loss_sum improved from 1.06905 to 0.99173, saving model to logs/scalars/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0029.ckpt\n",
      "61/61 [==============================] - 66s 1s/step - rpn_class_loss: 0.0403 - rpn_bbox_loss: 0.4665 - mrcnn_class_loss: 0.0560 - mrcnn_bbox_loss: 0.4596 - mrcnn_mask_loss: 0.3140 - l2_regularizer: 0.0083 - loss_sum: 1.3448 - val_rpn_class_loss: 0.0313 - val_rpn_bbox_loss: 0.2608 - val_mrcnn_class_loss: 0.0390 - val_mrcnn_bbox_loss: 0.3290 - val_mrcnn_mask_loss: 0.3317 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 0.9917 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "61/61 [==============================] - ETA: 0s - rpn_class_loss: 0.0349 - rpn_bbox_loss: 0.4208 - mrcnn_class_loss: 0.0511 - mrcnn_bbox_loss: 0.3698 - mrcnn_mask_loss: 0.3120 - l2_regularizer: 0.0083 - loss_sum: 1.1970\n",
      "Epoch 00030: val_loss_sum did not improve from 0.99173\n",
      "61/61 [==============================] - 66s 1s/step - rpn_class_loss: 0.0349 - rpn_bbox_loss: 0.4208 - mrcnn_class_loss: 0.0511 - mrcnn_bbox_loss: 0.3698 - mrcnn_mask_loss: 0.3120 - l2_regularizer: 0.0083 - loss_sum: 1.1970 - val_rpn_class_loss: 0.0352 - val_rpn_bbox_loss: 0.3865 - val_mrcnn_class_loss: 0.0437 - val_mrcnn_bbox_loss: 0.4445 - val_mrcnn_mask_loss: 0.2980 - val_l2_regularizer: 0.0000e+00 - val_loss_sum: 1.2079 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "train_model(model, \n",
    "            train_dataset=train_dataset,\n",
    "            val_dataset=val_dataset,\n",
    "            config=CONFIG, \n",
    "            weights_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
