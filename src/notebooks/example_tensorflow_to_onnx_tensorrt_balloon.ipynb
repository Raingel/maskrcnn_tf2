{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaskRCNN tensorflow to onnx conversion and TensorRT optimization. Balloon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs Memory limit: 1000\n",
      "Physical GPU-devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import onnx\n",
    "import subprocess\n",
    "from samples.balloon import balloon\n",
    "from model import mask_rcnn_functional\n",
    "from common.utils import tf_limit_gpu_memory\n",
    "from common import inference_utils\n",
    "from common.inference_optimize import maskrcnn_to_onnx, modify_onnx_model\n",
    "tf_limit_gpu_memory(tf, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.config import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-06-24T02:10:04.096601+03:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.7\n",
      "IPython version      : 7.16.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-65-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "tensorflow: 2.2.0\n",
      "onnx      : 1.8.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_shape': (512, 512, 3),\n",
       " 'img_size': 512,\n",
       " 'backbone': 'mobilenet',\n",
       " 'meta_shape': 14,\n",
       " 'num_classes': 2,\n",
       " 'class_dict': {'balloon': 1, 'background': 0},\n",
       " 'normalization': None,\n",
       " 'image_min_dim': 300,\n",
       " 'image_min_scale': 0,\n",
       " 'image_max_dim': 512,\n",
       " 'image_resize_mode': 'square',\n",
       " 'use_mini_masks': False,\n",
       " 'mini_mask_shape': (32, 32),\n",
       " 'mask_shape': (28, 28),\n",
       " 'epochs': 100,\n",
       " 'gpu_num': 1,\n",
       " 'batch_size': 1,\n",
       " 'images_per_gpu': 1,\n",
       " 'training': True,\n",
       " 'log_per_steps': 5,\n",
       " 'use_multiprocessing': True,\n",
       " 'workers': 6,\n",
       " 'callback': {'log_dir': 'logs/scalars',\n",
       "  'reduce_lr_on_plateau': 0.98,\n",
       "  'reduce_lr_on_plateau_patience': 10,\n",
       "  'save_weights_only': True,\n",
       "  'save_best_only': True,\n",
       "  'histogram_freq': 0,\n",
       "  'profile_batch': '1,2'},\n",
       " 'backbone_strides': [4, 8, 16, 32, 64],\n",
       " 'top_down_pyramid_size': 256,\n",
       " 'rpn_anchor_scales': (32, 64, 128, 256, 512),\n",
       " 'rpn_anchor_ratios': [0.5, 1, 2],\n",
       " 'rpn_anchor_stride': 1,\n",
       " 'rpn_train_anchors_per_image': 256,\n",
       " 'max_gt_instances': 100,\n",
       " 'rpn_bbox_std_dev': array([0.1, 0.1, 0.2, 0.2], dtype=float32),\n",
       " 'bbox_std_dev': array([0.1, 0.1, 0.2, 0.2], dtype=float32),\n",
       " 'rpn_nms_threshold': 0.7,\n",
       " 'use_rpn_rois': True,\n",
       " 'random_rois': 0,\n",
       " 'detection_min_confidence': 0.7,\n",
       " 'detection_nms_threshold': 0.3,\n",
       " 'detection_max_instances': 100,\n",
       " 'pre_nms_limit': 6000,\n",
       " 'post_nms_rois_training': 2000,\n",
       " 'post_nms_rois_inference': 1000,\n",
       " 'train_rois_per_image': 200,\n",
       " 'roi_positive_ratio': 0.33,\n",
       " 'pool_size': 7,\n",
       " 'mask_pool_size': 14,\n",
       " 'fpn_cls_fc_layers_size': 1024,\n",
       " 'loss_weights': [1, 1, 1, 1, 1],\n",
       " 'optimizer_kwargs': {'learning_rate': 0.001,\n",
       "  'clipvalue': 5.0,\n",
       "  'name': 'adamax'},\n",
       " 'weight_decay': 0.0002,\n",
       " 'train_bn': False,\n",
       " 'l2_reg_batchnorm': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG.update(balloon.BALLON_CONFIG)\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare inference graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0029.ckpt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = [x for x in os.listdir(f'../tests/samples/balloon') \n",
    "              if 'maskrcnn_%s' % CONFIG['backbone'] in x]\n",
    "checkpoint = checkpoint[0].split('.ckpt')[0] +'.ckpt'\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights path:\n",
      "../tests/samples/balloon/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0029.ckpt\n",
      "\n",
      "Model name:\n",
      "maskrcnn_mobilenet_512_512_3\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"\"\"maskrcnn_{CONFIG['backbone']}_{'_'.join(list(map(str, CONFIG['image_shape'])))}\"\"\" \n",
    "weights_path = os.path.join('..', 'tests', 'samples', 'balloon', checkpoint)\n",
    "print(f'Weights path:\\n{weights_path}\\n\\nModel name:\\n{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] Inference mode\n",
      "WARNING:tensorflow:Layer norm_boxes_anchors is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[MaskRCNN] Backbone architecture: mobilenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/envs/tf_env/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights for inference graph will be transferred from training graph\n",
      "\n",
      "[MaskRCNN] Training mode\n",
      "WARNING:tensorflow:Layer norm_boxes_anchors is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[MaskRCNN] Backbone architecture: mobilenet\n",
      "MaskRCNN Losses:\n",
      "rpn_class_loss: <layers.losses.RPNClassLoss object at 0x7f6cfc5b4b10>\n",
      "rpn_bbox_loss: <layers.losses.RPNBboxLoss object at 0x7f6cfc2d7950>\n",
      "mrcnn_class_loss: <layers.losses.MRCNNClassLoss object at 0x7f6cfc379bd0>\n",
      "mrcnn_bbox_loss: <layers.losses.MRCNNBboxLoss object at 0x7f6ce87c2b50>\n",
      "mrcnn_mask_loss: <layers.losses.MRCNNMaskLoss object at 0x7f6ce87c2c10>\n",
      "l2_regularizer: <layers.losses.L2RegLoss object at 0x7f6cfc233090>\n",
      "\n",
      "Set weights: conv1_pad\n",
      "Set weights: conv1\n",
      "Set weights: conv1_bn\n",
      "Set weights: conv1_relu\n",
      "Set weights: conv_dw_1\n",
      "Set weights: conv_dw_1_bn\n",
      "Set weights: conv_dw_1_relu\n",
      "Set weights: conv_pw_1\n",
      "Set weights: conv_pw_1_bn\n",
      "Set weights: conv_pw_1_relu\n",
      "Set weights: conv_pad_2\n",
      "Set weights: conv_dw_2\n",
      "Set weights: conv_dw_2_bn\n",
      "Set weights: conv_dw_2_relu\n",
      "Set weights: conv_pw_2\n",
      "Set weights: conv_pw_2_bn\n",
      "Set weights: conv_pw_2_relu\n",
      "Set weights: conv_dw_3\n",
      "Set weights: conv_dw_3_bn\n",
      "Set weights: conv_dw_3_relu\n",
      "Set weights: conv_pw_3\n",
      "Set weights: conv_pw_3_bn\n",
      "Set weights: conv_pw_3_relu\n",
      "Set weights: conv_pad_4\n",
      "Set weights: conv_dw_4\n",
      "Set weights: conv_dw_4_bn\n",
      "Set weights: conv_dw_4_relu\n",
      "Set weights: conv_pw_4\n",
      "Set weights: conv_pw_4_bn\n",
      "Set weights: conv_pw_4_relu\n",
      "Set weights: conv_dw_5\n",
      "Set weights: conv_dw_5_bn\n",
      "Set weights: conv_dw_5_relu\n",
      "Set weights: conv_pw_5\n",
      "Set weights: conv_pw_5_bn\n",
      "Set weights: conv_pw_5_relu\n",
      "Set weights: conv_pad_6\n",
      "Set weights: conv_dw_6\n",
      "Set weights: conv_dw_6_bn\n",
      "Set weights: conv_dw_6_relu\n",
      "Set weights: conv_pw_6\n",
      "Set weights: conv_pw_6_bn\n",
      "Set weights: conv_pw_6_relu\n",
      "Set weights: conv_dw_7\n",
      "Set weights: conv_dw_7_bn\n",
      "Set weights: conv_dw_7_relu\n",
      "Set weights: conv_pw_7\n",
      "Set weights: conv_pw_7_bn\n",
      "Set weights: conv_pw_7_relu\n",
      "Set weights: conv_dw_8\n",
      "Set weights: conv_dw_8_bn\n",
      "Set weights: conv_dw_8_relu\n",
      "Set weights: conv_pw_8\n",
      "Set weights: conv_pw_8_bn\n",
      "Set weights: conv_pw_8_relu\n",
      "Set weights: conv_dw_9\n",
      "Set weights: conv_dw_9_bn\n",
      "Set weights: conv_dw_9_relu\n",
      "Set weights: conv_pw_9\n",
      "Set weights: conv_pw_9_bn\n",
      "Set weights: conv_pw_9_relu\n",
      "Set weights: conv_dw_10\n",
      "Set weights: conv_dw_10_bn\n",
      "Set weights: conv_dw_10_relu\n",
      "Set weights: conv_pw_10\n",
      "Set weights: conv_pw_10_bn\n",
      "Set weights: conv_pw_10_relu\n",
      "Set weights: conv_dw_11\n",
      "Set weights: conv_dw_11_bn\n",
      "Set weights: conv_dw_11_relu\n",
      "Set weights: conv_pw_11\n",
      "Set weights: conv_pw_11_bn\n",
      "Set weights: conv_pw_11_relu\n",
      "Set weights: conv_pad_12\n",
      "Set weights: conv_dw_12\n",
      "Set weights: conv_dw_12_bn\n",
      "Set weights: conv_dw_12_relu\n",
      "Set weights: conv_pw_12\n",
      "Set weights: conv_pw_12_bn\n",
      "Set weights: conv_pw_12_relu\n",
      "Set weights: conv_dw_13\n",
      "Set weights: conv_dw_13_bn\n",
      "Set weights: conv_dw_13_relu\n",
      "Set weights: conv_pw_13\n",
      "Set weights: conv_pw_13_bn\n",
      "Set weights: conv_pw_13_relu\n",
      "Set weights: fpn_c5p5\n",
      "Set weights: fpn_c4p4\n",
      "Set weights: fpn_c3p3\n",
      "Set weights: fpn_c2p2\n",
      "Set weights: fpn_p5\n",
      "Set weights: fpn_p4\n",
      "Set weights: fpn_p3\n",
      "Set weights: fpn_p2\n",
      "Set weights: rpn_conv_shared\n",
      "Set weights: rpn_class_raw\n",
      "Skipped zero-weights layer:  activation\n",
      "Set weights: rpn_bbox_pred\n",
      "Skipped zero-weights layer:  lambda\n",
      "Skipped zero-weights layer:  activation_1\n",
      "Skipped zero-weights layer:  rpn_class_xxx\n",
      "Skipped zero-weights layer:  rpn_bbox_reshape\n",
      "Set weights: mrcnn_mask_conv1\n",
      "Set weights: mrcnn_mask_bn1\n",
      "Set weights: mrcnn_mask_conv2\n",
      "Set weights: mrcnn_mask_bn2\n",
      "Set weights: mrcnn_mask_conv3\n",
      "Set weights: mrcnn_mask_bn3\n",
      "Set weights: mrcnn_mask_conv4\n",
      "Set weights: mrcnn_mask_bn4\n",
      "Set weights: mrcnn_class_conv1\n",
      "Set weights: mrcnn_class_bn1\n",
      "Set weights: mrcnn_class_conv2\n",
      "Set weights: mrcnn_class_bn2\n",
      "Set weights: fpnclf_mrcnn_class_logits\n",
      "Set weights: fpnclf_mrcnn_bbox_fc\n",
      "Set weights: mrcnn_mask_deconv\n",
      "Set weights: mrcnn_mask\n",
      "Model: \"mask_rcnn_inference\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "backbone_mobilenet (Model)      [(None, 256, 256, 64 3228864     input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c5p5 (Conv2D)               (None, 16, 16, 256)  262400      backbone_mobilenet[1][4]         \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p5upsampled (UpSampling2D)  (None, 32, 32, 256)  0           fpn_c5p5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c4p4 (Conv2D)               (None, 32, 32, 256)  131328      backbone_mobilenet[1][3]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 32, 32, 256) 0           fpn_p5upsampled[0][0]            \n",
      "                                                                 fpn_c4p4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p4upsampled (UpSampling2D)  (None, 64, 64, 256)  0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c3p3 (Conv2D)               (None, 64, 64, 256)  65792       backbone_mobilenet[1][2]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 64, 64, 256) 0           fpn_p4upsampled[0][0]            \n",
      "                                                                 fpn_c3p3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p3upsampled (UpSampling2D)  (None, 128, 128, 256 0           tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c2p2 (Conv2D)               (None, 128, 128, 256 33024       backbone_mobilenet[1][1]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 128, 128, 25 0           fpn_p3upsampled[0][0]            \n",
      "                                                                 fpn_c2p2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p5 (Conv2D)                 (None, 16, 16, 256)  590080      fpn_c5p5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p2 (Conv2D)                 (None, 128, 128, 256 590080      tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p3 (Conv2D)                 (None, 64, 64, 256)  590080      tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p4 (Conv2D)                 (None, 32, 32, 256)  590080      tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p6 (MaxPooling2D)           (None, 8, 8, 256)    0           fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "rpn_model (Model)               ((None, None, 2), (N 1188864     fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "                                                                 fpn_p6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_rpn_class (Concatenate)  (None, None, 2)      0           rpn_model[1][1]                  \n",
      "                                                                 rpn_model[2][1]                  \n",
      "                                                                 rpn_model[3][1]                  \n",
      "                                                                 rpn_model[4][1]                  \n",
      "                                                                 rpn_model[5][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_rpn_bbox (Concatenate)   (None, None, 4)      0           rpn_model[1][2]                  \n",
      "                                                                 rpn_model[2][2]                  \n",
      "                                                                 rpn_model[3][2]                  \n",
      "                                                                 rpn_model[4][2]                  \n",
      "                                                                 rpn_model[5][2]                  \n",
      "__________________________________________________________________________________________________\n",
      "anchors (AnchorsLayer)          (1, 65472, 4)        261888      input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "roi (ProposalLayer)             (1, None, 4)         0           concat_rpn_class[0][0]           \n",
      "                                                                 concat_rpn_bbox[0][0]            \n",
      "                                                                 anchors[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_image_meta (InputLayer)   [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "roi_align_classifier (PyramidRO (1, None, 7, 7, 256) 0           roi[0][0]                        \n",
      "                                                                 input_image_meta[0][0]           \n",
      "                                                                 fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_conv1 (TimeDistribu (None, None, 1, 1, 1 12846080    roi_align_classifier[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_bn1 (TimeDistribute (None, None, 1, 1, 1 4096        mrcnn_class_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_relu_act1 (Activation)   (None, None, 1, 1, 1 0           mrcnn_class_bn1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_conv2 (TimeDistribu (None, None, 1, 1, 1 1049600     fpnclf_relu_act1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_bn2 (TimeDistribute (None, None, 1, 1, 1 4096        mrcnn_class_conv2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_relu_act2 (Activation)   (None, None, 1, 1, 1 0           mrcnn_class_bn2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_pool_squeeze (Reshape)   (None, 1000, 1024)   0           fpnclf_relu_act2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_class_logits (Time (None, 1000, 2)      2050        fpnclf_pool_squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_bbox_fc (TimeDistr (None, 1000, 8)      8200        fpnclf_pool_squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_class (TimeDistrib (None, 1000, 2)      0           fpnclf_mrcnn_class_logits[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_bbox_reshape (Resh (None, 1000, 2, 4)   0           fpnclf_mrcnn_bbox_fc[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_detection (DetectionLayer (1, 100, 6)          0           roi[0][0]                        \n",
      "                                                                 fpnclf_mrcnn_class[0][0]         \n",
      "                                                                 fpnclf_mrcnn_bbox_reshape[0][0]  \n",
      "                                                                 input_image_meta[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "detected_boxes_extraction (Dete (1, 100, 4)          0           mrcnn_detection[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "roi_align_mask (PyramidROIAlign (1, 100, 14, 14, 256 0           detected_boxes_extraction[0][0]  \n",
      "                                                                 input_image_meta[0][0]           \n",
      "                                                                 fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv1 (TimeDistribut (1, 100, 14, 14, 256 590080      roi_align_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn1 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act1 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv2 (TimeDistribut (1, 100, 14, 14, 256 590080      fpnmask_relu_act1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn2 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act2 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv3 (TimeDistribut (1, 100, 14, 14, 256 590080      fpnmask_relu_act2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn3 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act3 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv4 (TimeDistribut (1, 100, 14, 14, 256 590080      fpnmask_relu_act3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn4 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act4 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_deconv (TimeDistribu (1, 100, 28, 28, 256 262400      fpnmask_relu_act4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask (TimeDistributed)    (1, 100, 28, 28, 2)  514         mrcnn_mask_deconv[0][0]          \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 24,073,932\n",
      "Trainable params: 23,755,980\n",
      "Non-trainable params: 317,952\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Loading inference graph and import weights\n",
    "inference_config = CONFIG\n",
    "inference_config.update({'training': False})\n",
    "inference_model = mask_rcnn_functional(config=inference_config)\n",
    "inference_model = inference_utils.load_mrcnn_weights(model=inference_model,\n",
    "                                                     weights_path=weights_path,\n",
    "                                                     verbose=True\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert model to .onnx with tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexander/anaconda3/envs/tf_env/lib/python3.7/site-packages/tf2onnx/tf_loader.py:621: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot infer shape for mask_rcnn_inference/roi_align_classifier/Squeeze_1: mask_rcnn_inference/roi_align_classifier/Squeeze_1:0\n",
      "Cannot infer shape for mask_rcnn_inference/roi_align_classifier/Unique: mask_rcnn_inference/roi_align_classifier/Unique:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted from tensorflow to .onnx: ../weights/maskrcnn_mobilenet_512_512_3.onnx\n"
     ]
    }
   ],
   "source": [
    "input_spec = (\n",
    "    tf.TensorSpec((CONFIG['batch_size'], *CONFIG['image_shape']), tf.float32, name=\"input_image\"),\n",
    "    tf.TensorSpec((CONFIG['batch_size'], CONFIG['meta_shape']), tf.float32, name=\"input_image_meta\")\n",
    ")\n",
    "maskrcnn_to_onnx(model=inference_model, \n",
    "                 model_name = model_name,\n",
    "                 input_spec=input_spec,\n",
    "                 kwargs={'opset': 11}\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load onnx model and check it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph tf2onnx (\n",
      "  %input_image[FLOAT, 1x512x512x3]\n",
      "  %input_image_meta[FLOAT, 1x14]\n",
      ") initializers (\n",
      "  %slice_axes__590[INT32, 1]\n",
      "  %slice_axes__1150[INT32, 2]\n",
      "  %new_shape__1563[INT64, 4]\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Conv2D/ReadVariableOp:0[FLOAT, 512x256x3x3]\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D/ReadVariableOp:0[FLOAT, 12x512x1x1]\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D/ReadVariableOp:0[FLOAT, 6x512x1x1]\n",
      "  %mask_rcnn_inference/roi_align_mask/range/delta:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi_align_classifier/truediv/x:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/roi_align_classifier/range/start:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi_align_classifier/mul_2/y:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi_align_classifier/add/x:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi_align_classifier/PadV2/constant_values:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi/sub_4/x:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi/strided_slice_6:0[FLOAT, 65472x4]\n",
      "  %mask_rcnn_inference/roi/rpn_non_max_suppression/score_threshold:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/roi/mul_7/x:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/roi/mul/y:0[FLOAT, 1x1x4]\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose/ReadVariableOp:0[FLOAT, 256x256x2x2]\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/Conv2D/ReadVariableOp:0[FLOAT, 2x256x1x1]\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd/ReadVariableOp:0[FLOAT, 2]\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub_4/x:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_29/stack_2:0[INT32, 2]\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub_1/y:0[FLOAT, 4]\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub/y:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/mrcnn_detection/Reshape:0[INT32, 1000x1]\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/non_max_suppression/iou_threshold:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape_shape__2126[INT64, 1]\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Reshape_shape__1860[INT64, 2]\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/constant_values:0[INT64, scalar]\n",
      "  %mask_rcnn_inference/mrcnn_detection/Mul/y:0[FLOAT, 4]\n",
      "  %mask_rcnn_inference/mrcnn_detection/GreaterEqual/y:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/Conv2D/ReadVariableOp:0[FLOAT, 1024x1024x1x1]\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd/ReadVariableOp:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/conv2d/Conv2D/ReadVariableOp:0[FLOAT, 1024x256x7x7]\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd/ReadVariableOp:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp_1:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/MatMul/ReadVariableOp:0[FLOAT, 1024x2]\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/BiasAdd/ReadVariableOp:0[FLOAT, 2]\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_reshape/Reshape_shape__1861[INT64, 4]\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/MatMul/ReadVariableOp:0[FLOAT, 1024x8]\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/BiasAdd/ReadVariableOp:0[FLOAT, 8]\n",
      "  %mask_rcnn_inference/fpn_p5/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/fpn_p5/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_p4/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/fpn_p4/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_p3/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/fpn_p3/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_p2/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/fpn_p2/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_c5p5/Conv2D/ReadVariableOp:0[FLOAT, 256x1024x1x1]\n",
      "  %mask_rcnn_inference/fpn_c5p5/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_c4p4/Conv2D/ReadVariableOp:0[FLOAT, 256x512x1x1]\n",
      "  %mask_rcnn_inference/fpn_c4p4/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_c3p3/Conv2D/ReadVariableOp:0[FLOAT, 256x256x1x1]\n",
      "  %mask_rcnn_inference/fpn_c3p3/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_c2p2/Conv2D/ReadVariableOp:0[FLOAT, 256x128x1x1]\n",
      "  %mask_rcnn_inference/fpn_c2p2/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_9/Conv2D_weights_fused_bn[FLOAT, 512x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_9/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_8/Conv2D_weights_fused_bn[FLOAT, 512x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_8/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_7/Conv2D_weights_fused_bn[FLOAT, 512x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_7/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_6/Conv2D_weights_fused_bn[FLOAT, 512x256x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_6/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_5/Conv2D_weights_fused_bn[FLOAT, 256x256x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_5/Conv2D_bias_fused_bn[FLOAT, 256]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_4/Conv2D_weights_fused_bn[FLOAT, 256x128x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_4/Conv2D_bias_fused_bn[FLOAT, 256]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_3/Conv2D_weights_fused_bn[FLOAT, 128x128x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_3/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_2/Conv2D_weights_fused_bn[FLOAT, 128x64x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_2/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_13/Conv2D_weights_fused_bn[FLOAT, 1024x1024x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_13/Conv2D_bias_fused_bn[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_12/Conv2D_weights_fused_bn[FLOAT, 1024x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_12/Conv2D_bias_fused_bn[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_11/Conv2D_weights_fused_bn[FLOAT, 512x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_11/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_10/Conv2D_weights_fused_bn[FLOAT, 512x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_10/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_1/Conv2D_weights_fused_bn[FLOAT, 64x32x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_1/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_9/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_9/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_8/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_8/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_7/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_7/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_6/depthwise_weights_fused_bn[FLOAT, 256x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_6/depthwise_bias_fused_bn[FLOAT, 256]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_5/depthwise_weights_fused_bn[FLOAT, 256x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_5/depthwise_bias_fused_bn[FLOAT, 256]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_4/depthwise_weights_fused_bn[FLOAT, 128x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_4/depthwise_bias_fused_bn[FLOAT, 128]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_3/depthwise_weights_fused_bn[FLOAT, 128x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_3/depthwise_bias_fused_bn[FLOAT, 128]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_2/depthwise_weights_fused_bn[FLOAT, 64x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_2/depthwise_bias_fused_bn[FLOAT, 64]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_13/depthwise_weights_fused_bn[FLOAT, 1024x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_13/depthwise_bias_fused_bn[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_12/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_12/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_11/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_11/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_10/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_10/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_1/depthwise_weights_fused_bn[FLOAT, 32x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_1/depthwise_bias_fused_bn[FLOAT, 32]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D_weights_fused_bn[FLOAT, 32x3x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %end_masked__1262[INT32, 1]\n",
      "  %end_masked__1149[INT32, 2]\n",
      "  %const_two__306[INT64, 1]\n",
      "  %const_starts__54[INT64, 2]\n",
      "  %const_starts__478[INT64, 1]\n",
      "  %const_starts__449[INT64, 2]\n",
      "  %const_starts__441[INT64, 2]\n",
      "  %const_starts__371[INT64, 3]\n",
      "  %const_starts__1002[INT64, 2]\n",
      "  %const_fold_opt__1750[FLOAT, scalar]\n",
      "  %const_fold_opt__1749[INT64, 4]\n",
      "  %const_fold_opt__1746[INT64, 8]\n",
      "  %const_fold_opt__1743[INT64, 2]\n",
      "  %const_fold_opt__1741[INT32, 1]\n",
      "  %const_fold_opt__1740[INT64, scalar]\n",
      "  %const_fold_opt__1737[INT64, 2]\n",
      "  %const_fold_opt__1725[INT32, 1x2]\n",
      "  %const_fold_opt__1720[INT64, scalar]\n",
      "  %const_fold_opt__1714[FLOAT, scalar]\n",
      "  %const_fold_opt__1713[INT64, 4]\n",
      "  %const_fold_opt__1710[INT64, 2]\n",
      "  %const_fold_opt__1707[INT64, 2]\n",
      "  %const_fold_opt__1705[INT64, 2]\n",
      "  %const_fold_opt__1704[INT64, 3]\n",
      "  %const_fold_opt__1686[FLOAT, scalar]\n",
      "  %const_fold_opt__1684[INT64, 4]\n",
      "  %const_fold_opt__1670[INT64, 2]\n",
      "  %const_fold_opt__1663[INT32, 1]\n",
      "  %const_fold_opt__1661[INT64, 5]\n",
      "  %const_fold_opt__1658[INT64, 2]\n",
      "  %const_fold_opt__1657[INT64, 2]\n",
      "  %const_fold_opt__1656[INT64, 1]\n",
      "  %const_fold_opt__1651[FLOAT, scalar]\n",
      "  %const_fold_opt__1650[INT64, 5]\n",
      "  %const_fold_opt__1648[INT64, 3]\n",
      "  %const_fold_opt__1641[INT32, 1]\n",
      "  %const_fold_opt__1640[INT64, 4]\n",
      "  %const_fold_opt__1639[INT64, 3]\n",
      "  %const_fold_opt__1637[INT64, 3]\n",
      "  %const_ends__971[INT64, 2]\n",
      "  %const_ends__923[INT64, 1]\n",
      "  %const_ends__597[INT64, 2]\n",
      "  %const_ends__576[INT64, 2]\n",
      "  %const_ends__55[INT64, 2]\n",
      "  %const_ends__546[INT64, 1]\n",
      "  %const_ends__487[INT64, 1]\n",
      "  %const_ends__391[INT64, 1]\n",
      "  %const_ends__372[INT64, 3]\n",
      "  %const_ends__25[INT64, 2]\n",
      "  %const_ends__1445[INT64, 1]\n",
      "  %const_ends__1003[INT64, 2]\n",
      "  %const_empty_float__317[FLOAT, 0]\n",
      "  %const_axes__986[INT64, 2]\n",
      "  %const_axes__373[INT64, 3]\n",
      "  %cond__1350[BOOL, scalar]\n",
      "  %begin_masked__624[INT32, 1]\n",
      "  %begin_masked__1153[INT32, 2]\n",
      "  %ConstantFolding/mask_rcnn_inference/roi_align_mask/truediv_2_recip:0[FLOAT, scalar]\n",
      "  %ConstantFolding/mask_rcnn_inference/roi/split-folded-3:0[FLOAT, 1]\n",
      "  %ConstantFolding/mask_rcnn_inference/roi/split-folded-1:0[FLOAT, 1]\n",
      "  %Const__1560[INT64, 4]\n",
      "  %Const__1557[INT64, 4]\n",
      ") {\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D__22:0 = Transpose[perm = [0, 3, 1, 2]](%input_image)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv1_bn/FusedBatchNormV3:0 = Conv[auto_pad = 'NOTSET', dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [0, 0, 1, 1], strides = [2, 2]](%mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D__22:0, %mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv1_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv1_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 32, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv1_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_1_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_1_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_2:0 = Slice(%input_image_meta, %const_fold_opt__1743, %const_ends__25, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_6:0 = Slice(%mask_rcnn_inference/roi_align_mask/strided_slice_2:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_6__30:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_6:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_8:0 = Slice(%mask_rcnn_inference/roi_align_mask/strided_slice_6__30:0, %const_ends__391, %const_two__306, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_8__49:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_mask/strided_slice_8:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_7:0 = Slice(%mask_rcnn_inference/roi_align_mask/strided_slice_6__30:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_7__53:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_mask/strided_slice_7:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/mul:0 = Mul(%mask_rcnn_inference/roi_align_classifier/strided_slice_7__53:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_8__49:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Sqrt_1:0 = Sqrt(%mask_rcnn_inference/roi_align_classifier/mul:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/truediv:0 = Div(%mask_rcnn_inference/roi_align_classifier/truediv/x:0, %mask_rcnn_inference/roi_align_mask/Sqrt_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_7:0 = Slice(%mask_rcnn_inference/roi_align_mask/strided_slice_6__30:0, %const_starts__478, %const_two__306, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:1 = Split[axis = 0](%mask_rcnn_inference/mrcnn_detection/strided_slice_7:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/concat:0 = Concat[axis = 0](%mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:1, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:1)\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub:0 = Sub(%mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/concat:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub/y:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_3:0 = Slice(%input_image_meta, %const_starts__54, %const_ends__55, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub_1:0 = Sub(%mask_rcnn_inference/mrcnn_detection/strided_slice_3:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub_1/y:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/truediv:0 = Div(%mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub_1:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_11:0 = Slice(%mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/truediv:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_11__70:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_11:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/split:0, %mask_rcnn_inference/mrcnn_detection/split:1, %mask_rcnn_inference/mrcnn_detection/split:2, %mask_rcnn_inference/mrcnn_detection/split:3 = Split[axis = 0](%mask_rcnn_inference/mrcnn_detection/strided_slice_11__70:0)\n",
      "  %Split__1512:0, %Split__1512:1, %Split__1512:2, %Split__1512:3, %Split__1512:4, %Split__1512:5, %Split__1512:6, %Split__1512:7 = Split(%const_fold_opt__1746)\n",
      "  %Concat__1553:0 = Concat[axis = 0](%Split__1512:0, %Split__1512:3, %Split__1512:1, %Split__1512:2, %Split__1512:4, %Split__1512:7, %Split__1512:5, %Split__1512:6)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pad_2/Pad:0 = Pad(%mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6:0, %Concat__1553:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_2_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 64, kernel_shape = [3, 3], strides = [2, 2]](%mask_rcnn_inference/backbone_mobilenet/conv_pad_2/Pad:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_2/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_2/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_2_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_2_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_2_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_2_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_2/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_2/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_2_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_2_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_3_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_2_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_3/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_3/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_3_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_3_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_3_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_3_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_3/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_3/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_3_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_3_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/fpn_c2p2/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_3_relu/Relu6:0, %mask_rcnn_inference/fpn_c2p2/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_c2p2/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pad_4/Pad:0 = Pad(%mask_rcnn_inference/backbone_mobilenet/conv_pw_3_relu/Relu6:0, %Concat__1553:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], strides = [2, 2]](%mask_rcnn_inference/backbone_mobilenet/conv_pad_4/Pad:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_4_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_4_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_4/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_4/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_4_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_4_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_5_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_4_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_5/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_5/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_5_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_5_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_5_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_5_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_5/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_5/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_5_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_5_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/fpn_c3p3/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_5_relu/Relu6:0, %mask_rcnn_inference/fpn_c3p3/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_c3p3/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pad_6/Pad:0 = Pad(%mask_rcnn_inference/backbone_mobilenet/conv_pw_5_relu/Relu6:0, %Concat__1553:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_6_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], strides = [2, 2]](%mask_rcnn_inference/backbone_mobilenet/conv_pad_6/Pad:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_6/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_6/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_6_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_6_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_6_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_6_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_6/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_6/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_6_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_6_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_7_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_6_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_7/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_7/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_7_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_7_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_7_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_7_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_7/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_7/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_7_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_7_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_8_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_7_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_8/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_8/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_8_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_8_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_8_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_8_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_8/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_8/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_8_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_8_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_9_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_8_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_9/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_9/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_9_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_9_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_9_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_9_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_9/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_9/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_9_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_9_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_10_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_9_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_10/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_10/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_10_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_10_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_10_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_10_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_10/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_10/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_10_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_10_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/fpn_c4p4/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_10_relu/Relu6:0, %mask_rcnn_inference/fpn_c4p4/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_c4p4/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_11_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_10_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_11/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_11/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_11_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_11_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_11_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_11_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_11/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_11/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_11_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_11_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pad_12/Pad:0 = Pad(%mask_rcnn_inference/backbone_mobilenet/conv_pw_11_relu/Relu6:0, %Concat__1553:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_12_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], strides = [2, 2]](%mask_rcnn_inference/backbone_mobilenet/conv_pad_12/Pad:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_12/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_12/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_12_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_12_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_12_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_12_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_12/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_12/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_12_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_12_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_13_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1024, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_12_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_13/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_13/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_13_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_13_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_13_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_13_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_13/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_13/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_13_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_13_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__89)\n",
      "  %mask_rcnn_inference/fpn_c5p5/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_13_relu/Relu6:0, %mask_rcnn_inference/fpn_c5p5/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_c5p5/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/fpn_p5/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_c5p5/BiasAdd:0, %mask_rcnn_inference/fpn_p5/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_p5/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_conv_shared/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_p5/BiasAdd:0, %mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_conv_shared/Relu:0 = Relu(%mask_rcnn_inference/rpn_model_3/rpn_conv_shared/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_raw/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_3/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_raw/Conv2D__359:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_3/rpn_class_raw/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_logits_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_3/rpn_class_raw/Conv2D__359:0, %const_fold_opt__1639)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Max:0 = GlobalMaxPool(%mask_rcnn_inference/rpn_model_3/rpn_class_logits_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/sub:0 = Sub(%mask_rcnn_inference/rpn_model_3/rpn_class_logits_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Max:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Exp:0 = Exp(%mask_rcnn_inference/rpn_model_3/rpn_class_xxx/sub:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Sum:0 = ReduceSum[axes = [2], keepdims = 1](%mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Exp:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/truediv:0 = Div(%mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Exp:0, %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Sum:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_3/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D__362:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_bbox_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D__362:0, %const_fold_opt__1637)\n",
      "  %mask_rcnn_inference/fpn_p6/MaxPool:0 = MaxPool[kernel_shape = [1, 1], strides = [2, 2]](%mask_rcnn_inference/fpn_p5/BiasAdd:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_p6/MaxPool:0, %mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Relu:0 = Relu(%mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_raw/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_raw/Conv2D__369:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_4/rpn_class_raw/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_logits_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_4/rpn_class_raw/Conv2D__369:0, %const_fold_opt__1639)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Max:0 = GlobalMaxPool(%mask_rcnn_inference/rpn_model_4/rpn_class_logits_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/sub:0 = Sub(%mask_rcnn_inference/rpn_model_4/rpn_class_logits_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Max:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Exp:0 = Exp(%mask_rcnn_inference/rpn_model_4/rpn_class_xxx/sub:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Sum:0 = ReduceSum[axes = [2], keepdims = 1](%mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Exp:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/truediv:0 = Div(%mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Exp:0, %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Sum:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_bbox_pred/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_bbox_pred/Conv2D__395:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_4/rpn_bbox_pred/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_bbox_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_4/rpn_bbox_pred/Conv2D__395:0, %const_fold_opt__1637)\n",
      "  %Shape__1559:0 = Shape(%mask_rcnn_inference/fpn_c5p5/BiasAdd:0)\n",
      "  %Shape__1556:0 = Gather(%Shape__1559:0, %Const__1560)\n",
      "  %Shape__299:0 = Gather(%Shape__1556:0, %Const__1557)\n",
      "  %Slice__300:0 = Slice(%Shape__299:0, %const_starts__478, %const_two__306)\n",
      "  %Concat__302:0 = Concat[axis = 0](%Slice__300:0, %const_fold_opt__1737)\n",
      "  %Resize__303:0 = Resize[coordinate_transformation_mode = 'half_pixel', exclude_outside = 0, mode = 'nearest', nearest_mode = 'round_prefer_ceil'](%mask_rcnn_inference/fpn_c5p5/BiasAdd:0, %const_empty_float__317, %const_empty_float__317, %Concat__302:0)\n",
      "  %mask_rcnn_inference/tf_op_layer_AddV2/AddV2:0 = Add(%Resize__303:0, %mask_rcnn_inference/fpn_c4p4/BiasAdd:0)\n",
      "  %mask_rcnn_inference/fpn_p4/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/tf_op_layer_AddV2/AddV2:0, %mask_rcnn_inference/fpn_p4/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_p4/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_conv_shared/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_p4/BiasAdd:0, %mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_conv_shared/Relu:0 = Relu(%mask_rcnn_inference/rpn_model_2/rpn_conv_shared/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_2/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D__349:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_logits_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D__349:0, %const_fold_opt__1639)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Max:0 = GlobalMaxPool(%mask_rcnn_inference/rpn_model_2/rpn_class_logits_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/sub:0 = Sub(%mask_rcnn_inference/rpn_model_2/rpn_class_logits_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Max:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Exp:0 = Exp(%mask_rcnn_inference/rpn_model_2/rpn_class_xxx/sub:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Sum:0 = ReduceSum[axes = [2], keepdims = 1](%mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Exp:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/truediv:0 = Div(%mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Exp:0, %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Sum:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_bbox_pred/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_2/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_bbox_pred/Conv2D__352:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_2/rpn_bbox_pred/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_bbox_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_2/rpn_bbox_pred/Conv2D__352:0, %const_fold_opt__1637)\n",
      "  %Shape__309:0 = Shape(%mask_rcnn_inference/tf_op_layer_AddV2/AddV2:0)\n",
      "  %Slice__310:0 = Slice(%Shape__309:0, %const_starts__478, %const_two__306)\n",
      "  %Concat__312:0 = Concat[axis = 0](%Slice__310:0, %const_fold_opt__1658)\n",
      "  %Resize__313:0 = Resize[coordinate_transformation_mode = 'half_pixel', exclude_outside = 0, mode = 'nearest', nearest_mode = 'round_prefer_ceil'](%mask_rcnn_inference/tf_op_layer_AddV2/AddV2:0, %const_empty_float__317, %const_empty_float__317, %Concat__312:0)\n",
      "  %mask_rcnn_inference/tf_op_layer_AddV2_1/AddV2_1:0 = Add(%Resize__313:0, %mask_rcnn_inference/fpn_c3p3/BiasAdd:0)\n",
      "  %mask_rcnn_inference/fpn_p3/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/tf_op_layer_AddV2_1/AddV2_1:0, %mask_rcnn_inference/fpn_p3/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_p3/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_conv_shared/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_p3/BiasAdd:0, %mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_conv_shared/Relu:0 = Relu(%mask_rcnn_inference/rpn_model_1/rpn_conv_shared/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_raw/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_1/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_raw/Conv2D__339:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_1/rpn_class_raw/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_logits_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_1/rpn_class_raw/Conv2D__339:0, %const_fold_opt__1639)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Max:0 = GlobalMaxPool(%mask_rcnn_inference/rpn_model_1/rpn_class_logits_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/sub:0 = Sub(%mask_rcnn_inference/rpn_model_1/rpn_class_logits_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Max:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Exp:0 = Exp(%mask_rcnn_inference/rpn_model_1/rpn_class_xxx/sub:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Sum:0 = ReduceSum[axes = [2], keepdims = 1](%mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Exp:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/truediv:0 = Div(%mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Exp:0, %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Sum:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_1/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D__342:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_bbox_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D__342:0, %const_fold_opt__1637)\n",
      "  %Shape__319:0 = Shape(%mask_rcnn_inference/tf_op_layer_AddV2_1/AddV2_1:0)\n",
      "  %Slice__320:0 = Slice(%Shape__319:0, %const_starts__478, %const_two__306)\n",
      "  %Concat__322:0 = Concat[axis = 0](%Slice__320:0, %const_fold_opt__1657)\n",
      "  %Resize__323:0 = Resize[coordinate_transformation_mode = 'half_pixel', exclude_outside = 0, mode = 'nearest', nearest_mode = 'round_prefer_ceil'](%mask_rcnn_inference/tf_op_layer_AddV2_1/AddV2_1:0, %const_empty_float__317, %const_empty_float__317, %Concat__322:0)\n",
      "  %mask_rcnn_inference/tf_op_layer_AddV2_2/AddV2_2:0 = Add(%Resize__323:0, %mask_rcnn_inference/fpn_c2p2/BiasAdd:0)\n",
      "  %mask_rcnn_inference/fpn_p2/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/tf_op_layer_AddV2_2/AddV2_2:0, %mask_rcnn_inference/fpn_p2/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_p2/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_conv_shared/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_p2/BiasAdd:0, %mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_conv_shared/Relu:0 = Relu(%mask_rcnn_inference/rpn_model/rpn_conv_shared/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D__329:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_logits_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D__329:0, %const_fold_opt__1639)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_xxx/Max:0 = GlobalMaxPool(%mask_rcnn_inference/rpn_model/rpn_class_logits_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_xxx/sub:0 = Sub(%mask_rcnn_inference/rpn_model/rpn_class_logits_reshape/Reshape:0, %mask_rcnn_inference/rpn_model/rpn_class_xxx/Max:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_xxx/Exp:0 = Exp(%mask_rcnn_inference/rpn_model/rpn_class_xxx/sub:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_xxx/Sum:0 = ReduceSum[axes = [2], keepdims = 1](%mask_rcnn_inference/rpn_model/rpn_class_xxx/Exp:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_xxx/truediv:0 = Div(%mask_rcnn_inference/rpn_model/rpn_class_xxx/Exp:0, %mask_rcnn_inference/rpn_model/rpn_class_xxx/Sum:0)\n",
      "  %concat_rpn_class = Concat[axis = 1](%mask_rcnn_inference/rpn_model/rpn_class_xxx/truediv:0, %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/truediv:0, %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/truediv:0, %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/truediv:0, %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/truediv:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice:0 = Slice(%concat_rpn_class, %const_starts__371, %const_ends__372, %const_axes__373)\n",
      "  %mask_rcnn_inference/roi/strided_slice__374:0 = Squeeze[axes = [2]](%mask_rcnn_inference/roi/strided_slice:0)\n",
      "  %mask_rcnn_inference/roi/top_anchors:0, %mask_rcnn_inference/roi/top_anchors:1 = TopK[sorted = 1](%mask_rcnn_inference/roi/strided_slice__374:0, %const_fold_opt__1656)\n",
      "  %mask_rcnn_inference/roi/top_anchors__377:0 = Cast[to = 6](%mask_rcnn_inference/roi/top_anchors:1)\n",
      "  %mask_rcnn_inference/roi/strided_slice_3:0 = Slice(%mask_rcnn_inference/roi/top_anchors__377:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi/strided_slice_3__389:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_3:0)\n",
      "  %mask_rcnn_inference/roi/GatherV2_2:0 = Gather[axis = 0](%mask_rcnn_inference/roi/strided_slice_6:0, %mask_rcnn_inference/roi/strided_slice_3__389:0)\n",
      "  %mask_rcnn_inference/roi/pre_nms_anchors:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/GatherV2_2:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_8:0 = Slice(%mask_rcnn_inference/roi/pre_nms_anchors:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi/strided_slice_8__404:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_8:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_13:0 = Slice(%mask_rcnn_inference/roi/strided_slice_8__404:0, %const_axes__986, %const_ends__971, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi/strided_slice_13__416:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_13:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_12:0 = Slice(%mask_rcnn_inference/roi/strided_slice_8__404:0, %const_starts__1002, %const_ends__1003, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi/strided_slice_12__420:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_12:0)\n",
      "  %mask_rcnn_inference/roi/sub_1:0 = Sub(%mask_rcnn_inference/roi/strided_slice_12__420:0, %mask_rcnn_inference/roi/strided_slice_13__416:0)\n",
      "  %mask_rcnn_inference/roi/mul_2:0 = Mul(%mask_rcnn_inference/roi/mul_7/x:0, %mask_rcnn_inference/roi/sub_1:0)\n",
      "  %mask_rcnn_inference/roi/add_1:0 = Add(%mask_rcnn_inference/roi/strided_slice_13__416:0, %mask_rcnn_inference/roi/mul_2:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_11:0 = Slice(%mask_rcnn_inference/roi/strided_slice_8__404:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi/strided_slice_11__424:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_11:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_10:0 = Slice(%mask_rcnn_inference/roi/strided_slice_8__404:0, %const_starts__441, %const_ends__597, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi/strided_slice_10__428:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_10:0)\n",
      "  %mask_rcnn_inference/roi/sub:0 = Sub(%mask_rcnn_inference/roi/strided_slice_10__428:0, %mask_rcnn_inference/roi/strided_slice_11__424:0)\n",
      "  %mask_rcnn_inference/roi/mul_1:0 = Mul(%mask_rcnn_inference/roi/mul_7/x:0, %mask_rcnn_inference/roi/sub:0)\n",
      "  %mask_rcnn_inference/roi/add:0 = Add(%mask_rcnn_inference/roi/strided_slice_11__424:0, %mask_rcnn_inference/roi/mul_1:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_2:0 = Slice(%mask_rcnn_inference/roi/strided_slice__374:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi/strided_slice_2__393:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_2:0)\n",
      "  %mask_rcnn_inference/roi/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/roi/strided_slice_2__393:0, %mask_rcnn_inference/roi/strided_slice_3__389:0)\n",
      "  %mask_rcnn_inference/roi/packed:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/GatherV2:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_22:0 = Slice(%mask_rcnn_inference/roi/packed:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi/strided_slice_22__432:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_22:0)\n",
      "  %Unsqueeze__483:0 = Unsqueeze[axes = [0, 1]](%mask_rcnn_inference/roi/strided_slice_22__432:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_bbox_pred/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_bbox_pred/Conv2D__332:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model/rpn_bbox_pred/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_bbox_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model/rpn_bbox_pred/Conv2D__332:0, %const_fold_opt__1637)\n",
      "  %concat_rpn_bbox = Concat[axis = 1](%mask_rcnn_inference/rpn_model/rpn_bbox_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_1/rpn_bbox_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_2/rpn_bbox_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_3/rpn_bbox_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_4/rpn_bbox_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/roi/mul:0 = Mul(%concat_rpn_bbox, %mask_rcnn_inference/roi/mul/y:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_4:0 = Slice(%mask_rcnn_inference/roi/mul:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi/strided_slice_4__400:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_4:0)\n",
      "  %mask_rcnn_inference/roi/GatherV2_1:0 = Gather[axis = 0](%mask_rcnn_inference/roi/strided_slice_4__400:0, %mask_rcnn_inference/roi/strided_slice_3__389:0)\n",
      "  %mask_rcnn_inference/roi/packed_1:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/GatherV2_1:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_9:0 = Slice(%mask_rcnn_inference/roi/packed_1:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi/strided_slice_9__436:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_9:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_19:0 = Slice(%mask_rcnn_inference/roi/strided_slice_9__436:0, %const_starts__1002, %const_ends__1003, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi/strided_slice_19__440:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_19:0)\n",
      "  %mask_rcnn_inference/roi/Exp_1:0 = Exp(%mask_rcnn_inference/roi/strided_slice_19__440:0)\n",
      "  %mask_rcnn_inference/roi/mul_6:0 = Mul(%mask_rcnn_inference/roi/sub_1:0, %mask_rcnn_inference/roi/Exp_1:0)\n",
      "  %mask_rcnn_inference/roi/mul_8:0 = Mul(%mask_rcnn_inference/roi/mul_7/x:0, %mask_rcnn_inference/roi/mul_6:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_18:0 = Slice(%mask_rcnn_inference/roi/strided_slice_9__436:0, %const_starts__441, %const_ends__597, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi/strided_slice_18__444:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_18:0)\n",
      "  %mask_rcnn_inference/roi/Exp:0 = Exp(%mask_rcnn_inference/roi/strided_slice_18__444:0)\n",
      "  %mask_rcnn_inference/roi/mul_5:0 = Mul(%mask_rcnn_inference/roi/sub:0, %mask_rcnn_inference/roi/Exp:0)\n",
      "  %mask_rcnn_inference/roi/mul_7:0 = Mul(%mask_rcnn_inference/roi/mul_7/x:0, %mask_rcnn_inference/roi/mul_5:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_17:0 = Slice(%mask_rcnn_inference/roi/strided_slice_9__436:0, %const_axes__986, %const_ends__971, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi/strided_slice_17__448:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_17:0)\n",
      "  %mask_rcnn_inference/roi/mul_4:0 = Mul(%mask_rcnn_inference/roi/strided_slice_17__448:0, %mask_rcnn_inference/roi/sub_1:0)\n",
      "  %mask_rcnn_inference/roi/add_3:0 = Add(%mask_rcnn_inference/roi/add_1:0, %mask_rcnn_inference/roi/mul_4:0)\n",
      "  %mask_rcnn_inference/roi/sub_3:0 = Sub(%mask_rcnn_inference/roi/add_3:0, %mask_rcnn_inference/roi/mul_8:0)\n",
      "  %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__454:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi/sub_3:0)\n",
      "  %mask_rcnn_inference/roi/add_5:0 = Add(%mask_rcnn_inference/roi/sub_3:0, %mask_rcnn_inference/roi/mul_6:0)\n",
      "  %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__456:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi/add_5:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_16:0 = Slice(%mask_rcnn_inference/roi/strided_slice_9__436:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi/strided_slice_16__452:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_16:0)\n",
      "  %mask_rcnn_inference/roi/mul_3:0 = Mul(%mask_rcnn_inference/roi/strided_slice_16__452:0, %mask_rcnn_inference/roi/sub:0)\n",
      "  %mask_rcnn_inference/roi/add_2:0 = Add(%mask_rcnn_inference/roi/add:0, %mask_rcnn_inference/roi/mul_3:0)\n",
      "  %mask_rcnn_inference/roi/sub_2:0 = Sub(%mask_rcnn_inference/roi/add_2:0, %mask_rcnn_inference/roi/mul_7:0)\n",
      "  %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__453:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi/sub_2:0)\n",
      "  %mask_rcnn_inference/roi/add_4:0 = Add(%mask_rcnn_inference/roi/sub_2:0, %mask_rcnn_inference/roi/mul_5:0)\n",
      "  %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__455:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi/add_4:0)\n",
      "  %mask_rcnn_inference/roi/apply_box_deltas_out_Concat__457:0 = Concat[axis = 1](%mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__453:0, %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__454:0, %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__455:0, %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__456:0)\n",
      "  %mask_rcnn_inference/roi/refined_anchors:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/apply_box_deltas_out_Concat__457:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_20:0 = Slice(%mask_rcnn_inference/roi/refined_anchors:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi/strided_slice_20__461:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_20:0)\n",
      "  %mask_rcnn_inference/roi/split_1:0, %mask_rcnn_inference/roi/split_1:1, %mask_rcnn_inference/roi/split_1:2, %mask_rcnn_inference/roi/split_1:3 = Split[axis = 1](%mask_rcnn_inference/roi/strided_slice_20__461:0)\n",
      "  %Min__474:0 = Min(%mask_rcnn_inference/roi/split_1:0, %ConstantFolding/mask_rcnn_inference/roi/split-folded-3:0)\n",
      "  %Max__476:0 = Max(%Min__474:0, %ConstantFolding/mask_rcnn_inference/roi/split-folded-1:0)\n",
      "  %Min__470:0 = Min(%mask_rcnn_inference/roi/split_1:1, %ConstantFolding/mask_rcnn_inference/roi/split-folded-3:0)\n",
      "  %Max__472:0 = Max(%Min__470:0, %ConstantFolding/mask_rcnn_inference/roi/split-folded-1:0)\n",
      "  %Min__466:0 = Min(%mask_rcnn_inference/roi/split_1:2, %ConstantFolding/mask_rcnn_inference/roi/split-folded-3:0)\n",
      "  %Max__468:0 = Max(%Min__466:0, %ConstantFolding/mask_rcnn_inference/roi/split-folded-1:0)\n",
      "  %Min__462:0 = Min(%mask_rcnn_inference/roi/split_1:3, %ConstantFolding/mask_rcnn_inference/roi/split-folded-3:0)\n",
      "  %Max__464:0 = Max(%Min__462:0, %ConstantFolding/mask_rcnn_inference/roi/split-folded-1:0)\n",
      "  %mask_rcnn_inference/roi/clipped_boxes:0 = Concat[axis = 1](%Max__476:0, %Max__472:0, %Max__468:0, %Max__464:0)\n",
      "  %mask_rcnn_inference/roi/refined_anchors_clipped:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/clipped_boxes:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_21:0 = Slice(%mask_rcnn_inference/roi/refined_anchors_clipped:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi/strided_slice_21__481:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_21:0)\n",
      "  %Unsqueeze__482:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_21__481:0)\n",
      "  %NonMaxSuppression__485:0 = NonMaxSuppression(%Unsqueeze__482:0, %Unsqueeze__483:0, %const_fold_opt__1720, %mask_rcnn_inference/mrcnn_detection/GreaterEqual/y:0, %mask_rcnn_inference/roi/rpn_non_max_suppression/score_threshold:0)\n",
      "  %Slice__489:0 = Slice(%NonMaxSuppression__485:0, %const_two__306, %const_ends__487, %const_ends__391)\n",
      "  %Squeeze__491:0 = Squeeze[axes = [1]](%Slice__489:0)\n",
      "  %mask_rcnn_inference/roi/rpn_non_max_suppression/NonMaxSuppressionV3:0 = Cast[to = 6](%Squeeze__491:0)\n",
      "  %mask_rcnn_inference/roi/GatherV2_3:0 = Gather[axis = 0](%mask_rcnn_inference/roi/strided_slice_21__481:0, %mask_rcnn_inference/roi/rpn_non_max_suppression/NonMaxSuppressionV3:0)\n",
      "  %mask_rcnn_inference/roi/Shape_1:0 = Shape(%mask_rcnn_inference/roi/GatherV2_3:0)\n",
      "  %mask_rcnn_inference/roi/Shape_1__494:0 = Cast[to = 6](%mask_rcnn_inference/roi/Shape_1:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_23:0 = Slice(%mask_rcnn_inference/roi/Shape_1__494:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi/strided_slice_23__498:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_23:0)\n",
      "  %mask_rcnn_inference/roi/sub_4:0 = Sub(%mask_rcnn_inference/roi/sub_4/x:0, %mask_rcnn_inference/roi/strided_slice_23__498:0)\n",
      "  %Cast__499:0 = Cast[to = 1](%mask_rcnn_inference/roi/sub_4:0)\n",
      "  %Max__501:0 = Max(%Cast__499:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137)\n",
      "  %Max__501__502:0 = Cast[to = 6](%Max__501:0)\n",
      "  %mask_rcnn_inference/roi/Pad/paddings/0_Unsqueeze__505:0 = Unsqueeze[axes = [0]](%Max__501__502:0)\n",
      "  %mask_rcnn_inference/roi/Pad/paddings/0_Concat__506:0 = Concat[axis = 0](%slice_axes__590, %mask_rcnn_inference/roi/Pad/paddings/0_Unsqueeze__505:0)\n",
      "  %mask_rcnn_inference/roi/Pad/paddings_Unsqueeze__507:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/Pad/paddings/0_Concat__506:0)\n",
      "  %mask_rcnn_inference/roi/Pad/paddings_Concat__509:0 = Concat[axis = 0](%mask_rcnn_inference/roi/Pad/paddings_Unsqueeze__507:0, %const_fold_opt__1725)\n",
      "  %mask_rcnn_inference/roi/Pad__510:0 = Cast[to = 7](%mask_rcnn_inference/roi/Pad/paddings_Concat__509:0)\n",
      "  %mask_rcnn_inference/roi/Pad__511:0 = Transpose(%mask_rcnn_inference/roi/Pad__510:0)\n",
      "  %mask_rcnn_inference/roi/Pad__513:0 = Reshape(%mask_rcnn_inference/roi/Pad__511:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape_shape__2126)\n",
      "  %mask_rcnn_inference/roi/Pad:0 = Pad(%mask_rcnn_inference/roi/GatherV2_3:0, %mask_rcnn_inference/roi/Pad__513:0)\n",
      "  %roi = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/Pad:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/split:0, %mask_rcnn_inference/roi_align_classifier/split:1, %mask_rcnn_inference/roi_align_classifier/split:2, %mask_rcnn_inference/roi_align_classifier/split:3 = Split[axis = 2](%roi)\n",
      "  %mask_rcnn_inference/roi_align_classifier/sub_1:0 = Sub(%mask_rcnn_inference/roi_align_classifier/split:3, %mask_rcnn_inference/roi_align_classifier/split:1)\n",
      "  %mask_rcnn_inference/roi_align_classifier/sub:0 = Sub(%mask_rcnn_inference/roi_align_classifier/split:2, %mask_rcnn_inference/roi_align_classifier/split:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/mul_1:0 = Mul(%mask_rcnn_inference/roi_align_classifier/sub:0, %mask_rcnn_inference/roi_align_classifier/sub_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Sqrt:0 = Sqrt(%mask_rcnn_inference/roi_align_classifier/mul_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/truediv_1:0 = Div(%mask_rcnn_inference/roi_align_classifier/Sqrt:0, %mask_rcnn_inference/roi_align_classifier/truediv:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Log:0 = Log(%mask_rcnn_inference/roi_align_classifier/truediv_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/truediv_2:0 = Mul(%mask_rcnn_inference/roi_align_classifier/Log:0, %ConstantFolding/mask_rcnn_inference/roi_align_mask/truediv_2_recip:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Round:0 = Round(%mask_rcnn_inference/roi_align_classifier/truediv_2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Round:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/add:0 = Add(%mask_rcnn_inference/roi_align_classifier/add/x:0, %mask_rcnn_inference/roi_align_classifier/Cast:0)\n",
      "  %Cast__515:0 = Cast[to = 1](%mask_rcnn_inference/roi_align_classifier/add:0)\n",
      "  %Max__518:0 = Max(%const_fold_opt__1750, %Cast__515:0)\n",
      "  %Max__518__521:0 = Cast[to = 6](%Max__518:0)\n",
      "  %Cast__526:0 = Cast[to = 1](%Max__518__521:0)\n",
      "  %Min__529:0 = Min(%const_fold_opt__1651, %Cast__526:0)\n",
      "  %Min__529__532:0 = Cast[to = 6](%Min__529:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Squeeze:0 = Squeeze[axes = [2]](%Min__529__532:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Squeeze_1:0 = Squeeze(%mask_rcnn_inference/roi_align_classifier/Squeeze:0)\n",
      "  %Cast__536:0 = Cast[to = 7](%mask_rcnn_inference/roi_align_classifier/Squeeze_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Unique:0, %mask_rcnn_inference/roi_align_classifier/Unique:1, %mask_rcnn_inference/roi_align_classifier/Unique:2 = Unique[sorted = 0](%Cast__536:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Unique__537_cast:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Unique:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/PadV2:0 = Pad(%mask_rcnn_inference/roi_align_classifier/Unique__537_cast:0, %const_fold_opt__1743, %mask_rcnn_inference/roi_align_classifier/PadV2/constant_values:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_9:0 = Slice(%mask_rcnn_inference/roi_align_classifier/PadV2:0, %const_starts__478, %const_ends__546, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_classifier/split_1:0, %mask_rcnn_inference/roi_align_classifier/split_1:1, %mask_rcnn_inference/roi_align_classifier/split_1:2, %mask_rcnn_inference/roi_align_classifier/split_1:3 = Split[axis = 0](%mask_rcnn_inference/roi_align_classifier/strided_slice_9:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Equal_3:0 = Equal(%mask_rcnn_inference/roi_align_classifier/Squeeze:0, %mask_rcnn_inference/roi_align_classifier/split_1:3)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Where_3:0 = NonZero(%mask_rcnn_inference/roi_align_classifier/Equal_3:0)\n",
      "  %where_op_added__548:0 = Transpose(%mask_rcnn_inference/roi_align_classifier/Where_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_13:0 = Slice(%where_op_added__548:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_13__554:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_13:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast_4:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/strided_slice_13__554:0)\n",
      "  %Size__672:0 = Size(%mask_rcnn_inference/roi_align_classifier/Cast_4:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Equal_2:0 = Equal(%mask_rcnn_inference/roi_align_classifier/Squeeze:0, %mask_rcnn_inference/roi_align_classifier/split_1:2)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Where_2:0 = NonZero(%mask_rcnn_inference/roi_align_classifier/Equal_2:0)\n",
      "  %where_op_added__556:0 = Transpose(%mask_rcnn_inference/roi_align_classifier/Where_2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_12:0 = Slice(%where_op_added__556:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_12__562:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_12:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast_3:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/strided_slice_12__562:0)\n",
      "  %Size__718:0 = Size(%mask_rcnn_inference/roi_align_classifier/Cast_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Equal_1:0 = Equal(%mask_rcnn_inference/roi_align_classifier/Squeeze:0, %mask_rcnn_inference/roi_align_classifier/split_1:1)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Where_1:0 = NonZero(%mask_rcnn_inference/roi_align_classifier/Equal_1:0)\n",
      "  %where_op_added__564:0 = Transpose(%mask_rcnn_inference/roi_align_classifier/Where_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_11:0 = Slice(%where_op_added__564:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_11__570:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_11:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast_2:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/strided_slice_11__570:0)\n",
      "  %Size__764:0 = Size(%mask_rcnn_inference/roi_align_classifier/Cast_2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Equal:0 = Equal(%mask_rcnn_inference/roi_align_classifier/Squeeze:0, %mask_rcnn_inference/roi_align_classifier/split_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Where:0 = NonZero(%mask_rcnn_inference/roi_align_classifier/Equal:0)\n",
      "  %where_op_added__572:0 = Transpose(%mask_rcnn_inference/roi_align_classifier/Where:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_10:0 = Slice(%where_op_added__572:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_10__578:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_10:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast_1:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/strided_slice_10__578:0)\n",
      "  %Size__810:0 = Size(%mask_rcnn_inference/roi_align_classifier/Cast_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/concat_1:0 = Concat[axis = 0](%where_op_added__572:0, %where_op_added__564:0, %where_op_added__556:0, %where_op_added__548:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_1:0 = Shape(%roi)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape__627:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Shape_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_24:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Shape__627:0, %const_starts__478, %const_two__306, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_16:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Shape__627:0, %const_ends__391, %const_two__306, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_17:0 = Slice(%mask_rcnn_inference/roi_align_classifier/concat_1:0, %slice_axes__590, %mask_rcnn_inference/roi_align_classifier/strided_slice_16:0, %slice_axes__590, %const_fold_opt__1741)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_2:0 = Shape(%mask_rcnn_inference/roi_align_classifier/strided_slice_17:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_2__591:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Shape_2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_18:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Shape_2__591:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_18__595:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_classifier/strided_slice_18:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/range:0 = Range(%mask_rcnn_inference/roi_align_classifier/range/start:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_18__595:0, %mask_rcnn_inference/roi_align_mask/range/delta:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/ExpandDims:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/range:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast_5:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/strided_slice_17:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/concat_2:0 = Concat[axis = 1](%mask_rcnn_inference/roi_align_classifier/Cast_5:0, %mask_rcnn_inference/roi_align_classifier/ExpandDims:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_23:0 = Slice(%mask_rcnn_inference/roi_align_classifier/concat_2:0, %const_starts__441, %const_ends__597, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_23__599:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_23:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_20:0 = Slice(%mask_rcnn_inference/roi_align_classifier/concat_2:0, %const_axes__986, %const_ends__971, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_20__604:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_20:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_19:0 = Slice(%mask_rcnn_inference/roi_align_classifier/concat_2:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_19__609:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_19:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/mul_2:0 = Mul(%mask_rcnn_inference/roi_align_classifier/strided_slice_19__609:0, %mask_rcnn_inference/roi_align_classifier/mul_2/y:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/add_1:0 = Add(%mask_rcnn_inference/roi_align_classifier/mul_2:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_20__604:0)\n",
      "  %Cast__618:0 = Cast[to = 1](%mask_rcnn_inference/roi_align_classifier/add_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_3:0 = Shape(%mask_rcnn_inference/roi_align_classifier/concat_2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_3__611:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Shape_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_21:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Shape_3__611:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_21__615:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_classifier/strided_slice_21:0)\n",
      "  %Cast__616:0 = Cast[to = 7](%mask_rcnn_inference/roi_align_classifier/strided_slice_21__615:0)\n",
      "  %Unsqueeze__617:0 = Unsqueeze[axes = [0]](%Cast__616:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/TopKV2:0, %mask_rcnn_inference/roi_align_classifier/TopKV2:1 = TopK[sorted = 1](%Cast__618:0, %Unsqueeze__617:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/TopKV2__622:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/TopKV2:1)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_22:0 = Slice(%mask_rcnn_inference/roi_align_classifier/TopKV2__622:0, %begin_masked__624, %end_masked__1262, %slice_axes__590, %const_fold_opt__1641)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/roi_align_classifier/strided_slice_23__599:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_22:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherNd_3:0 = GatherND(%roi, %where_op_added__548:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3:0 = Loop[body = <graph tf2onnx__635>](%Size__672:0, %cond__1350)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherNd_2:0 = GatherND(%roi, %where_op_added__556:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2:0 = Loop[body = <graph tf2onnx__681>](%Size__718:0, %cond__1350)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherNd_1:0 = GatherND(%roi, %where_op_added__564:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1:0 = Loop[body = <graph tf2onnx__727>](%Size__764:0, %cond__1350)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherNd:0 = GatherND(%roi, %where_op_added__572:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize:0 = Loop[body = <graph tf2onnx__773>](%Size__810:0, %cond__1350)\n",
      "  %mask_rcnn_inference/roi_align_classifier/concat:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_15:0 = Slice(%mask_rcnn_inference/roi_align_classifier/concat:0, %slice_axes__590, %mask_rcnn_inference/roi_align_classifier/strided_slice_16:0, %slice_axes__590, %const_fold_opt__1741)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherV2_1:0 = Gather[axis = 0](%mask_rcnn_inference/roi_align_classifier/strided_slice_15:0, %mask_rcnn_inference/roi_align_classifier/GatherV2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_5:0 = Shape(%mask_rcnn_inference/roi_align_classifier/GatherV2_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_5__818:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Shape_5:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_25:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Shape_5__818:0, %const_ends__391, %const_ends__923, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_classifier/concat_3:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/strided_slice_24:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_25:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Reshape__822:0 = Cast[to = 7](%mask_rcnn_inference/roi_align_classifier/concat_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Reshape:0 = Reshape(%mask_rcnn_inference/roi_align_classifier/GatherV2_1:0, %mask_rcnn_inference/roi_align_classifier/Reshape__822:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Shape:0 = Shape(%mask_rcnn_inference/roi_align_classifier/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Shape__823:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_class_conv1/Shape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/strided_slice:0 = Slice(%mask_rcnn_inference/mrcnn_class_conv1/Shape__823:0, %const_ends__391, %const_two__306, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Reshape_1/shape_Concat__833:0 = Concat[axis = 0](%const_fold_opt__1641, %mask_rcnn_inference/mrcnn_class_conv1/strided_slice:0, %const_fold_opt__1741, %const_fold_opt__1741, %const_fold_opt__1663)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Reshape_1__839:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_class_conv1/Reshape_1/shape_Concat__833:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Reshape:0 = Reshape(%mask_rcnn_inference/roi_align_classifier/Reshape:0, %const_fold_opt__1713)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd__835:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_class_conv1/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], strides = [1, 1]](%mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd__835:0, %mask_rcnn_inference/mrcnn_class_conv1/conv2d/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd:0, %mask_rcnn_inference/mrcnn_class_conv1/Reshape_1__839:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Shape:0 = Shape(%mask_rcnn_inference/mrcnn_class_conv1/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Shape__840:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_class_bn1/Shape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/strided_slice:0 = Slice(%mask_rcnn_inference/mrcnn_class_bn1/Shape__840:0, %const_ends__391, %const_two__306, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Reshape_1/shape_Concat__850:0 = Concat[axis = 0](%const_fold_opt__1641, %mask_rcnn_inference/mrcnn_class_bn1/strided_slice:0, %const_fold_opt__1741, %const_fold_opt__1741, %const_fold_opt__1663)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Reshape_1__856:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_class_bn1/Reshape_1/shape_Concat__850:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_class_conv1/Reshape_1:0, %const_fold_opt__1684)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3__852:0 = Reshape(%mask_rcnn_inference/mrcnn_class_bn1/Reshape:0, %new_shape__1563)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3__852:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3:0, %mask_rcnn_inference/mrcnn_class_bn1/Reshape_1__856:0)\n",
      "  %mask_rcnn_inference/fpnclf_relu_act1/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_class_bn1/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd__869:0 = Reshape(%mask_rcnn_inference/fpnclf_relu_act1/Relu:0, %new_shape__1563)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd__869:0, %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/Shape:0 = Shape(%mask_rcnn_inference/fpnclf_relu_act1/Relu:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/Shape__857:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_class_conv2/Shape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/strided_slice:0 = Slice(%mask_rcnn_inference/mrcnn_class_conv2/Shape__857:0, %const_ends__391, %const_two__306, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/Reshape_1/shape_Concat__867:0 = Concat[axis = 0](%const_fold_opt__1641, %mask_rcnn_inference/mrcnn_class_conv2/strided_slice:0, %const_fold_opt__1741, %const_fold_opt__1741, %const_fold_opt__1663)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/Reshape_1__873:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_class_conv2/Reshape_1/shape_Concat__867:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd:0, %mask_rcnn_inference/mrcnn_class_conv2/Reshape_1__873:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Shape:0 = Shape(%mask_rcnn_inference/mrcnn_class_conv2/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Shape__874:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_class_bn2/Shape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/strided_slice:0 = Slice(%mask_rcnn_inference/mrcnn_class_bn2/Shape__874:0, %const_ends__391, %const_two__306, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Reshape_1/shape_Concat__884:0 = Concat[axis = 0](%const_fold_opt__1641, %mask_rcnn_inference/mrcnn_class_bn2/strided_slice:0, %const_fold_opt__1741, %const_fold_opt__1741, %const_fold_opt__1663)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Reshape_1__890:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_class_bn2/Reshape_1/shape_Concat__884:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_class_conv2/Reshape_1:0, %const_fold_opt__1684)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/FusedBatchNormV3__886:0 = Reshape(%mask_rcnn_inference/mrcnn_class_bn2/Reshape:0, %new_shape__1563)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/FusedBatchNormV3__886:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/FusedBatchNormV3:0, %mask_rcnn_inference/mrcnn_class_bn2/Reshape_1__890:0)\n",
      "  %mask_rcnn_inference/fpnclf_relu_act2/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_class_bn2/Reshape_1:0)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/Reshape:0 = Reshape(%mask_rcnn_inference/fpnclf_relu_act2/Relu:0, %const_fold_opt__1710)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/MatMul:0 = MatMul(%mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/Reshape:0, %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/MatMul/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/BiasAdd:0 = Add(%mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/MatMul:0, %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class/Reshape:0 = Reshape(%mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/BiasAdd:0, %const_fold_opt__1707)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class/activation_2/Softmax:0 = Softmax[axis = 1](%mask_rcnn_inference/fpnclf_mrcnn_class/Reshape:0)\n",
      "  %fpnclf_mrcnn_class = Reshape(%mask_rcnn_inference/fpnclf_mrcnn_class/activation_2/Softmax:0, %const_fold_opt__1704)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_9:0 = Slice(%fpnclf_mrcnn_class, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_9__908:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_9:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/ArgMax:0 = ArgMax[axis = 1, keepdims = 0](%mask_rcnn_inference/mrcnn_detection/strided_slice_9__908:0)\n",
      "  %Cast__910:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/ArgMax:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Reshape_1:0 = Reshape(%Cast__910:0, %const_fold_opt__1670)\n",
      "  %mask_rcnn_inference/mrcnn_detection/concat:0 = Concat[axis = 1](%mask_rcnn_inference/mrcnn_detection/Reshape:0, %mask_rcnn_inference/mrcnn_detection/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherNd_1__961:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_detection/concat:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherNd:0 = GatherND(%mask_rcnn_inference/mrcnn_detection/strided_slice_9__908:0, %mask_rcnn_inference/mrcnn_detection/GatherNd_1__961:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GreaterEqual:0 = Less(%mask_rcnn_inference/mrcnn_detection/GatherNd:0, %mask_rcnn_inference/mrcnn_detection/GreaterEqual/y:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GreaterEqual__913:0 = Not(%mask_rcnn_inference/mrcnn_detection/GreaterEqual:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Where_1:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/GreaterEqual__913:0)\n",
      "  %where_op_added__914:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/Where_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_25:0 = Slice(%where_op_added__914:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_25__919:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_25:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/strided_slice_25__919:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape_shape__2126)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Greater__930:0 = Cast[to = 1](%Cast__910:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Greater:0 = Greater(%mask_rcnn_inference/mrcnn_detection/Greater__930:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6_min__137)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Where:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/Greater:0)\n",
      "  %where_op_added__932:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/Where:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_24:0 = Slice(%where_op_added__932:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_24__937:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_24:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Reshape_2:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/strided_slice_24__937:0, %const_fold_opt__1705)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Equal:0 = Equal(%mask_rcnn_inference/mrcnn_detection/strided_slice_25__919:0, %mask_rcnn_inference/mrcnn_detection/Reshape_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Cast:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/Equal:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Sum:0 = ReduceSum[axes = [0], keepdims = 0](%mask_rcnn_inference/mrcnn_detection/Cast:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask/Where:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/Sum:0)\n",
      "  %where_op_added__940:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/boolean_mask/Where:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask/Squeeze:0 = Squeeze[axes = [1]](%where_op_added__940:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/boolean_mask/Reshape:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask/Squeeze:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Reshape_3:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0, %const_fold_opt__1705)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_1:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/GatherNd:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/GatherV2_1:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape_shape__2126)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2:0 = Gather[axis = 0](%Cast__910:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/MatMul:0 = MatMul(%mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/Reshape:0, %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/MatMul/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/BiasAdd:0 = Add(%mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/MatMul:0, %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/BiasAdd/ReadVariableOp:0)\n",
      "  %fpnclf_mrcnn_bbox_reshape = Reshape(%mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/BiasAdd:0, %mask_rcnn_inference/fpnclf_mrcnn_bbox_reshape/Reshape_shape__1861)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_10:0 = Slice(%fpnclf_mrcnn_bbox_reshape, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_10__959:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_10:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherNd_1:0 = GatherND(%mask_rcnn_inference/mrcnn_detection/strided_slice_10__959:0, %mask_rcnn_inference/mrcnn_detection/GatherNd_1__961:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Mul:0 = Mul(%mask_rcnn_inference/mrcnn_detection/GatherNd_1:0, %mask_rcnn_inference/mrcnn_detection/Mul/y:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_23:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Mul:0, %const_starts__1002, %const_ends__1003, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_23__965:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_23:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Exp_1:0 = Exp(%mask_rcnn_inference/mrcnn_detection/strided_slice_23__965:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_22:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Mul:0, %const_starts__441, %const_ends__597, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_22__969:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_22:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Exp:0 = Exp(%mask_rcnn_inference/mrcnn_detection/strided_slice_22__969:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_21:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Mul:0, %const_axes__986, %const_ends__971, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_21__973:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_21:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_20:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Mul:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_20__977:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_20:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_8:0 = Slice(%roi, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_8__981:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_8:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_18:0 = Slice(%mask_rcnn_inference/mrcnn_detection/strided_slice_8__981:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_15__1011:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_18:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_17:0 = Slice(%mask_rcnn_inference/mrcnn_detection/strided_slice_8__981:0, %const_axes__986, %const_ends__971, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_17__999:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_17:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_16:0 = Slice(%mask_rcnn_inference/mrcnn_detection/strided_slice_8__981:0, %const_starts__1002, %const_ends__1003, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_16__1005:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_16:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub_1:0 = Sub(%mask_rcnn_inference/mrcnn_detection/strided_slice_16__1005:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_17__999:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_6:0 = Mul(%mask_rcnn_inference/mrcnn_detection/sub_1:0, %mask_rcnn_inference/mrcnn_detection/Exp_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_8:0 = Mul(%mask_rcnn_inference/roi/mul_7/x:0, %mask_rcnn_inference/mrcnn_detection/mul_6:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_4:0 = Mul(%mask_rcnn_inference/mrcnn_detection/strided_slice_21__973:0, %mask_rcnn_inference/mrcnn_detection/sub_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_2:0 = Mul(%mask_rcnn_inference/roi/mul_7/x:0, %mask_rcnn_inference/mrcnn_detection/sub_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add_1:0 = Add(%mask_rcnn_inference/mrcnn_detection/strided_slice_17__999:0, %mask_rcnn_inference/mrcnn_detection/mul_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add_3:0 = Add(%mask_rcnn_inference/mrcnn_detection/add_1:0, %mask_rcnn_inference/mrcnn_detection/mul_4:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub_3:0 = Sub(%mask_rcnn_inference/mrcnn_detection/add_3:0, %mask_rcnn_inference/mrcnn_detection/mul_8:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1021:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/sub_3:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add_5:0 = Add(%mask_rcnn_inference/mrcnn_detection/sub_3:0, %mask_rcnn_inference/mrcnn_detection/mul_6:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1023:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/add_5:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_14:0 = Slice(%mask_rcnn_inference/mrcnn_detection/strided_slice_8__981:0, %const_starts__441, %const_ends__597, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_14__1017:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_14:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub:0 = Sub(%mask_rcnn_inference/mrcnn_detection/strided_slice_14__1017:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_15__1011:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_5:0 = Mul(%mask_rcnn_inference/mrcnn_detection/sub:0, %mask_rcnn_inference/mrcnn_detection/Exp:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_7:0 = Mul(%mask_rcnn_inference/roi/mul_7/x:0, %mask_rcnn_inference/mrcnn_detection/mul_5:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_3:0 = Mul(%mask_rcnn_inference/mrcnn_detection/strided_slice_20__977:0, %mask_rcnn_inference/mrcnn_detection/sub:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_1:0 = Mul(%mask_rcnn_inference/roi/mul_7/x:0, %mask_rcnn_inference/mrcnn_detection/sub:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add:0 = Add(%mask_rcnn_inference/mrcnn_detection/strided_slice_15__1011:0, %mask_rcnn_inference/mrcnn_detection/mul_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add_2:0 = Add(%mask_rcnn_inference/mrcnn_detection/add:0, %mask_rcnn_inference/mrcnn_detection/mul_3:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub_2:0 = Sub(%mask_rcnn_inference/mrcnn_detection/add_2:0, %mask_rcnn_inference/mrcnn_detection/mul_7:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1020:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/sub_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add_4:0 = Add(%mask_rcnn_inference/mrcnn_detection/sub_2:0, %mask_rcnn_inference/mrcnn_detection/mul_5:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1022:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/add_4:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Concat__1024:0 = Concat[axis = 1](%mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1020:0, %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1021:0, %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1022:0, %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1023:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/split_1:0, %mask_rcnn_inference/mrcnn_detection/split_1:1, %mask_rcnn_inference/mrcnn_detection/split_1:2, %mask_rcnn_inference/mrcnn_detection/split_1:3 = Split[axis = 1](%mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Concat__1024:0)\n",
      "  %Min__1037:0 = Min(%mask_rcnn_inference/mrcnn_detection/split_1:0, %mask_rcnn_inference/mrcnn_detection/split:2)\n",
      "  %Max__1039:0 = Max(%Min__1037:0, %mask_rcnn_inference/mrcnn_detection/split:0)\n",
      "  %Min__1033:0 = Min(%mask_rcnn_inference/mrcnn_detection/split_1:1, %mask_rcnn_inference/mrcnn_detection/split:3)\n",
      "  %Max__1035:0 = Max(%Min__1033:0, %mask_rcnn_inference/mrcnn_detection/split:1)\n",
      "  %Min__1029:0 = Min(%mask_rcnn_inference/mrcnn_detection/split_1:2, %mask_rcnn_inference/mrcnn_detection/split:2)\n",
      "  %Max__1031:0 = Max(%Min__1029:0, %mask_rcnn_inference/mrcnn_detection/split:0)\n",
      "  %Min__1025:0 = Min(%mask_rcnn_inference/mrcnn_detection/split_1:3, %mask_rcnn_inference/mrcnn_detection/split:3)\n",
      "  %Max__1027:0 = Max(%Min__1025:0, %mask_rcnn_inference/mrcnn_detection/split:1)\n",
      "  %mask_rcnn_inference/mrcnn_detection/clipped_boxes:0 = Concat[axis = 1](%Max__1039:0, %Max__1035:0, %Max__1031:0, %Max__1027:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/clipped_boxes:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/GatherV2_2:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Reshape_shape__1860)\n",
      "  %Cast__1064:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_detection/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Unique:0, %mask_rcnn_inference/mrcnn_detection/Unique:1, %mask_rcnn_inference/mrcnn_detection/Unique:2 = Unique[sorted = 0](%Cast__1064:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Unique__1067_cast:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/Unique:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/Unique__1067_cast:0, %const_fold_opt__1705)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Equal:0 = Equal(%mask_rcnn_inference/mrcnn_detection/GatherV2:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Cast:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/Equal:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Sum:0 = ReduceSum[axes = [0], keepdims = 0](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/Cast:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Where:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/Sum:0)\n",
      "  %where_op_added__1075:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Where:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Squeeze:0 = Squeeze[axes = [1]](%where_op_added__1075:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Squeeze:0)\n",
      "  %Unsqueeze__1082:0 = Unsqueeze[axes = [0, 1]](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Reshape:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Squeeze:0)\n",
      "  %Unsqueeze__1080:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/GatherV2:0)\n",
      "  %NonMaxSuppression__1085:0 = NonMaxSuppression(%Unsqueeze__1080:0, %Unsqueeze__1082:0, %const_fold_opt__1740, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/non_max_suppression/iou_threshold:0, %mask_rcnn_inference/roi/rpn_non_max_suppression/score_threshold:0)\n",
      "  %Slice__1091:0 = Slice(%NonMaxSuppression__1085:0, %const_two__306, %const_ends__487, %const_ends__391)\n",
      "  %Squeeze__1093:0 = Squeeze[axes = [1]](%Slice__1091:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/non_max_suppression/NonMaxSuppressionV3:0 = Cast[to = 6](%Squeeze__1093:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/non_max_suppression/NonMaxSuppressionV3:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Shape:0 = Shape(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Shape__1096:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/Shape:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/strided_slice:0 = Slice(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/Shape__1096:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/strided_slice__1100:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/strided_slice:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/sub:0 = Sub(%mask_rcnn_inference/mrcnn_detection/sub_4/x:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/strided_slice__1100:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings/0_Unsqueeze__1102:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/sub:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings/0_Concat__1103:0 = Concat[axis = 0](%slice_axes__590, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings/0_Unsqueeze__1102:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings/0_Concat__1103:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1104:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1105:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1104:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1107:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1105:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape_shape__2126)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2:0 = Pad(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/GatherV2:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1107:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/constant_values:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Greater_1__1108:0 = Cast[to = 1](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Greater_1:0 = Greater(%mask_rcnn_inference/mrcnn_detection/Greater_1__1108:0, %const_fold_opt__1686)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Where_2:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/Greater_1:0)\n",
      "  %where_op_added__1111:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/Where_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_26:0 = Slice(%where_op_added__1111:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_26__1117:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_26:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_3:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_26__1117:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/GatherV2_3:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape_shape__2126)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Equal_1:0 = Equal(%mask_rcnn_inference/mrcnn_detection/GatherV2_3:0, %mask_rcnn_inference/mrcnn_detection/Reshape_3:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Cast_1:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/Equal_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Sum_1:0 = ReduceSum[axes = [0], keepdims = 0](%mask_rcnn_inference/mrcnn_detection/Cast_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Where:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/Sum_1:0)\n",
      "  %where_op_added__1129:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Where:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Squeeze:0 = Squeeze[axes = [1]](%where_op_added__1129:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Squeeze:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_4:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/GatherNd:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Shape_2:0 = Shape(%mask_rcnn_inference/mrcnn_detection/GatherV2_4:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Shape_2__1132:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/Shape_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_27:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Shape_2__1132:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_27__1136:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_27:0)\n",
      "  %Cast__1137:0 = Cast[to = 1](%mask_rcnn_inference/mrcnn_detection/strided_slice_27__1136:0)\n",
      "  %Min__1139:0 = Min(%Cast__1137:0, %const_fold_opt__1714)\n",
      "  %Min__1139__1140:0 = Cast[to = 6](%Min__1139:0)\n",
      "  %Cast__1142:0 = Cast[to = 7](%Min__1139__1140:0)\n",
      "  %Unsqueeze__1143:0 = Unsqueeze[axes = [0]](%Cast__1142:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/TopKV2:0, %mask_rcnn_inference/mrcnn_detection/TopKV2:1 = TopK[sorted = 1](%mask_rcnn_inference/mrcnn_detection/GatherV2_4:0, %Unsqueeze__1143:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/TopKV2__1144:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/TopKV2:1)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_5:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/boolean_mask_1/GatherV2:0, %mask_rcnn_inference/mrcnn_detection/TopKV2__1144:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_8:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/GatherNd:0, %mask_rcnn_inference/mrcnn_detection/GatherV2_5:0)\n",
      "  %Unsqueeze__1146:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/GatherV2_8:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_29:0 = Slice(%Unsqueeze__1146:0, %begin_masked__1153, %end_masked__1149, %slice_axes__1150, %mask_rcnn_inference/mrcnn_detection/strided_slice_29/stack_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_7:0 = Gather[axis = 0](%Cast__910:0, %mask_rcnn_inference/mrcnn_detection/GatherV2_5:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Cast_2:0 = Cast[to = 1](%mask_rcnn_inference/mrcnn_detection/GatherV2_7:0)\n",
      "  %Unsqueeze__1151:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/Cast_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_28:0 = Slice(%Unsqueeze__1151:0, %begin_masked__1153, %end_masked__1149, %slice_axes__1150, %mask_rcnn_inference/mrcnn_detection/strided_slice_29/stack_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_6:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/clipped_boxes:0, %mask_rcnn_inference/mrcnn_detection/GatherV2_5:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/concat_1:0 = Concat[axis = 1](%mask_rcnn_inference/mrcnn_detection/GatherV2_6:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_28:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_29:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Shape_3:0 = Shape(%mask_rcnn_inference/mrcnn_detection/concat_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Shape_3__1156:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/Shape_3:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_30:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Shape_3__1156:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_30__1160:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_30:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub_4:0 = Sub(%mask_rcnn_inference/mrcnn_detection/sub_4/x:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_30__1160:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad/paddings/0_Unsqueeze__1162:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/sub_4:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad/paddings/0_Concat__1163:0 = Concat[axis = 0](%slice_axes__590, %mask_rcnn_inference/mrcnn_detection/Pad/paddings/0_Unsqueeze__1162:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad/paddings_Unsqueeze__1164:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/Pad/paddings/0_Concat__1163:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad/paddings_Concat__1166:0 = Concat[axis = 0](%mask_rcnn_inference/mrcnn_detection/Pad/paddings_Unsqueeze__1164:0, %const_fold_opt__1725)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad__1167:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_detection/Pad/paddings_Concat__1166:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad__1168:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/Pad__1167:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad__1170:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/Pad__1168:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape_shape__2126)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad:0 = Pad(%mask_rcnn_inference/mrcnn_detection/concat_1:0, %mask_rcnn_inference/mrcnn_detection/Pad__1170:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/packed:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/Pad:0)\n",
      "  %mrcnn_detection = Reshape(%mask_rcnn_inference/mrcnn_detection/packed:0, %const_fold_opt__1648)\n",
      "  %mask_rcnn_inference/detected_boxes_extraction/strided_slice:0 = Slice(%mrcnn_detection, %const_starts__478, %const_ends__546, %const_two__306)\n",
      "  %mask_rcnn_inference/roi_align_mask/split:0, %mask_rcnn_inference/roi_align_mask/split:1, %mask_rcnn_inference/roi_align_mask/split:2, %mask_rcnn_inference/roi_align_mask/split:3 = Split[axis = 2](%mask_rcnn_inference/detected_boxes_extraction/strided_slice:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/sub_1:0 = Sub(%mask_rcnn_inference/roi_align_mask/split:3, %mask_rcnn_inference/roi_align_mask/split:1)\n",
      "  %mask_rcnn_inference/roi_align_mask/sub:0 = Sub(%mask_rcnn_inference/roi_align_mask/split:2, %mask_rcnn_inference/roi_align_mask/split:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/mul_1:0 = Mul(%mask_rcnn_inference/roi_align_mask/sub:0, %mask_rcnn_inference/roi_align_mask/sub_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Sqrt:0 = Sqrt(%mask_rcnn_inference/roi_align_mask/mul_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/truediv_1:0 = Div(%mask_rcnn_inference/roi_align_mask/Sqrt:0, %mask_rcnn_inference/roi_align_classifier/truediv:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Log:0 = Log(%mask_rcnn_inference/roi_align_mask/truediv_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/truediv_2:0 = Mul(%mask_rcnn_inference/roi_align_mask/Log:0, %ConstantFolding/mask_rcnn_inference/roi_align_mask/truediv_2_recip:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Round:0 = Round(%mask_rcnn_inference/roi_align_mask/truediv_2:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/Round:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/add:0 = Add(%mask_rcnn_inference/roi_align_classifier/add/x:0, %mask_rcnn_inference/roi_align_mask/Cast:0)\n",
      "  %Cast__1176:0 = Cast[to = 1](%mask_rcnn_inference/roi_align_mask/add:0)\n",
      "  %Max__1177:0 = Max(%const_fold_opt__1750, %Cast__1176:0)\n",
      "  %Max__1177__1178:0 = Cast[to = 6](%Max__1177:0)\n",
      "  %Cast__1181:0 = Cast[to = 1](%Max__1177__1178:0)\n",
      "  %Min__1182:0 = Min(%const_fold_opt__1651, %Cast__1181:0)\n",
      "  %Min__1182__1183:0 = Cast[to = 6](%Min__1182:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Squeeze:0 = Squeeze[axes = [2]](%Min__1182__1183:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Squeeze_1:0 = Squeeze(%mask_rcnn_inference/roi_align_mask/Squeeze:0)\n",
      "  %Cast__1185:0 = Cast[to = 7](%mask_rcnn_inference/roi_align_mask/Squeeze_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Unique:0, %mask_rcnn_inference/roi_align_mask/Unique:1, %mask_rcnn_inference/roi_align_mask/Unique:2 = Unique[sorted = 0](%Cast__1185:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Unique__1186_cast:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/Unique:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/PadV2:0 = Pad(%mask_rcnn_inference/roi_align_mask/Unique__1186_cast:0, %const_fold_opt__1743, %mask_rcnn_inference/roi_align_classifier/PadV2/constant_values:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_9:0 = Slice(%mask_rcnn_inference/roi_align_mask/PadV2:0, %const_starts__478, %const_ends__546, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_mask/split_1:0, %mask_rcnn_inference/roi_align_mask/split_1:1, %mask_rcnn_inference/roi_align_mask/split_1:2, %mask_rcnn_inference/roi_align_mask/split_1:3 = Split[axis = 0](%mask_rcnn_inference/roi_align_mask/strided_slice_9:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Equal_3:0 = Equal(%mask_rcnn_inference/roi_align_mask/Squeeze:0, %mask_rcnn_inference/roi_align_mask/split_1:3)\n",
      "  %mask_rcnn_inference/roi_align_mask/Where_3:0 = NonZero(%mask_rcnn_inference/roi_align_mask/Equal_3:0)\n",
      "  %where_op_added__1197:0 = Transpose(%mask_rcnn_inference/roi_align_mask/Where_3:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_13:0 = Slice(%where_op_added__1197:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_13__1202:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_13:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast_4:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/strided_slice_13__1202:0)\n",
      "  %Size__1303:0 = Size(%mask_rcnn_inference/roi_align_mask/Cast_4:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Equal_2:0 = Equal(%mask_rcnn_inference/roi_align_mask/Squeeze:0, %mask_rcnn_inference/roi_align_mask/split_1:2)\n",
      "  %mask_rcnn_inference/roi_align_mask/Where_2:0 = NonZero(%mask_rcnn_inference/roi_align_mask/Equal_2:0)\n",
      "  %where_op_added__1204:0 = Transpose(%mask_rcnn_inference/roi_align_mask/Where_2:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_12:0 = Slice(%where_op_added__1204:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_12__1209:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_12:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast_3:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/strided_slice_12__1209:0)\n",
      "  %Size__1348:0 = Size(%mask_rcnn_inference/roi_align_mask/Cast_3:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Equal_1:0 = Equal(%mask_rcnn_inference/roi_align_mask/Squeeze:0, %mask_rcnn_inference/roi_align_mask/split_1:1)\n",
      "  %mask_rcnn_inference/roi_align_mask/Where_1:0 = NonZero(%mask_rcnn_inference/roi_align_mask/Equal_1:0)\n",
      "  %where_op_added__1211:0 = Transpose(%mask_rcnn_inference/roi_align_mask/Where_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_11:0 = Slice(%where_op_added__1211:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_11__1216:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_11:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast_2:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/strided_slice_11__1216:0)\n",
      "  %Size__1393:0 = Size(%mask_rcnn_inference/roi_align_mask/Cast_2:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Equal:0 = Equal(%mask_rcnn_inference/roi_align_mask/Squeeze:0, %mask_rcnn_inference/roi_align_mask/split_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Where:0 = NonZero(%mask_rcnn_inference/roi_align_mask/Equal:0)\n",
      "  %where_op_added__1218:0 = Transpose(%mask_rcnn_inference/roi_align_mask/Where:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_10:0 = Slice(%where_op_added__1218:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_10__1223:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_10:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast_1:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/strided_slice_10__1223:0)\n",
      "  %Size__1438:0 = Size(%mask_rcnn_inference/roi_align_mask/Cast_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/concat_1:0 = Concat[axis = 0](%where_op_added__1218:0, %where_op_added__1211:0, %where_op_added__1204:0, %where_op_added__1197:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_17:0 = Slice(%mask_rcnn_inference/roi_align_mask/concat_1:0, %const_starts__478, %const_ends__1445, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_mask/Shape_2:0 = Shape(%mask_rcnn_inference/roi_align_mask/strided_slice_17:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Shape_2__1228:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/Shape_2:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_18:0 = Slice(%mask_rcnn_inference/roi_align_mask/Shape_2__1228:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_18__1232:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_mask/strided_slice_18:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/range:0 = Range(%mask_rcnn_inference/roi_align_classifier/range/start:0, %mask_rcnn_inference/roi_align_mask/strided_slice_18__1232:0, %mask_rcnn_inference/roi_align_mask/range/delta:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/ExpandDims:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/range:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast_5:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/strided_slice_17:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/concat_2:0 = Concat[axis = 1](%mask_rcnn_inference/roi_align_mask/Cast_5:0, %mask_rcnn_inference/roi_align_mask/ExpandDims:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_23:0 = Slice(%mask_rcnn_inference/roi_align_mask/concat_2:0, %const_starts__441, %const_ends__597, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_23__1236:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_23:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_20:0 = Slice(%mask_rcnn_inference/roi_align_mask/concat_2:0, %const_axes__986, %const_ends__971, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_20__1241:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_20:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_19:0 = Slice(%mask_rcnn_inference/roi_align_mask/concat_2:0, %const_starts__449, %const_ends__576, %const_axes__986)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_19__1246:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_19:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/mul_2:0 = Mul(%mask_rcnn_inference/roi_align_mask/strided_slice_19__1246:0, %mask_rcnn_inference/roi_align_classifier/mul_2/y:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/add_1:0 = Add(%mask_rcnn_inference/roi_align_mask/mul_2:0, %mask_rcnn_inference/roi_align_mask/strided_slice_20__1241:0)\n",
      "  %Cast__1255:0 = Cast[to = 1](%mask_rcnn_inference/roi_align_mask/add_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Shape_3:0 = Shape(%mask_rcnn_inference/roi_align_mask/concat_2:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Shape_3__1248:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/Shape_3:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_21:0 = Slice(%mask_rcnn_inference/roi_align_mask/Shape_3__1248:0, %const_starts__478, %const_ends__391, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_21__1252:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_mask/strided_slice_21:0)\n",
      "  %Cast__1253:0 = Cast[to = 7](%mask_rcnn_inference/roi_align_mask/strided_slice_21__1252:0)\n",
      "  %Unsqueeze__1254:0 = Unsqueeze[axes = [0]](%Cast__1253:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/TopKV2:0, %mask_rcnn_inference/roi_align_mask/TopKV2:1 = TopK[sorted = 1](%Cast__1255:0, %Unsqueeze__1254:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/TopKV2__1259:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/TopKV2:1)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_22:0 = Slice(%mask_rcnn_inference/roi_align_mask/TopKV2__1259:0, %begin_masked__624, %end_masked__1262, %slice_axes__590, %const_fold_opt__1641)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/roi_align_mask/strided_slice_23__1236:0, %mask_rcnn_inference/roi_align_mask/strided_slice_22:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherNd_3:0 = GatherND(%mask_rcnn_inference/detected_boxes_extraction/strided_slice:0, %where_op_added__1197:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3:0 = Loop[body = <graph tf2onnx__1267>](%Size__1303:0, %cond__1350)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherNd_2:0 = GatherND(%mask_rcnn_inference/detected_boxes_extraction/strided_slice:0, %where_op_added__1204:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2:0 = Loop[body = <graph tf2onnx__1312>](%Size__1348:0, %cond__1350)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherNd_1:0 = GatherND(%mask_rcnn_inference/detected_boxes_extraction/strided_slice:0, %where_op_added__1211:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1:0 = Loop[body = <graph tf2onnx__1357>](%Size__1393:0, %cond__1350)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherNd:0 = GatherND(%mask_rcnn_inference/detected_boxes_extraction/strided_slice:0, %where_op_added__1218:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize:0 = Loop[body = <graph tf2onnx__1402>](%Size__1438:0, %cond__1350)\n",
      "  %mask_rcnn_inference/roi_align_mask/concat:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_15:0 = Slice(%mask_rcnn_inference/roi_align_mask/concat:0, %const_starts__478, %const_ends__1445, %const_starts__478)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherV2_1:0 = Gather[axis = 0](%mask_rcnn_inference/roi_align_mask/strided_slice_15:0, %mask_rcnn_inference/roi_align_mask/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/Reshape:0 = Reshape(%mask_rcnn_inference/roi_align_mask/GatherV2_1:0, %const_fold_opt__1640)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd__1449:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_conv1/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd__1449:0, %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd__1450:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd__1450:0, %const_fold_opt__1640)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3__1453:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_bn1/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3__1453:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3__1454:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3__1454:0, %const_fold_opt__1650)\n",
      "  %mask_rcnn_inference/fpnmask_relu_act1/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_mask_bn1/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/Reshape:0 = Reshape(%mask_rcnn_inference/fpnmask_relu_act1/Relu:0, %const_fold_opt__1640)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd__1457:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_conv2/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd__1457:0, %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd__1458:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd__1458:0, %const_fold_opt__1640)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3__1461:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_bn2/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3__1461:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3__1462:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3__1462:0, %const_fold_opt__1650)\n",
      "  %mask_rcnn_inference/fpnmask_relu_act2/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_mask_bn2/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/Reshape:0 = Reshape(%mask_rcnn_inference/fpnmask_relu_act2/Relu:0, %const_fold_opt__1640)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd__1465:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_conv3/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd__1465:0, %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd__1466:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd__1466:0, %const_fold_opt__1640)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3__1469:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_bn3/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3__1469:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3__1470:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3__1470:0, %const_fold_opt__1650)\n",
      "  %mask_rcnn_inference/fpnmask_relu_act3/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_mask_bn3/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/Reshape:0 = Reshape(%mask_rcnn_inference/fpnmask_relu_act3/Relu:0, %const_fold_opt__1640)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd__1473:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_conv4/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd__1473:0, %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd__1474:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd__1474:0, %const_fold_opt__1640)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3__1477:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_bn4/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3__1477:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3__1478:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3__1478:0, %const_fold_opt__1650)\n",
      "  %mask_rcnn_inference/fpnmask_relu_act4/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_mask_bn4/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/Reshape:0 = Reshape(%mask_rcnn_inference/fpnmask_relu_act4/Relu:0, %const_fold_opt__1640)\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose__1481:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_deconv/Reshape:0)\n",
      "  %ConvTranspose__1549:0 = ConvTranspose[auto_pad = 'NOTSET', dilations = [1, 1], kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose__1481:0, %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/Relu:0 = Relu(%ConvTranspose__1549:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose__1482:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/Relu:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose__1482:0, %const_fold_opt__1749)\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd__1485:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd__1485:0, %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/Sigmoid:0 = Sigmoid(%mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd__1486:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/Sigmoid:0)\n",
      "  %mrcnn_mask = Reshape(%mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd__1486:0, %const_fold_opt__1661)\n",
      "  return %mrcnn_detection, %fpnclf_mrcnn_class, %fpnclf_mrcnn_bbox_reshape, %mrcnn_mask, %roi, %concat_rpn_class, %concat_rpn_bbox\n",
      "}\n",
      "\n",
      "graph tf2onnx__635 (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_i__632[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_cond__633[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero_zero__646[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero_long__639[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero__638[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one_one__647[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one_long__641[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one__640[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_four__648[INT64, 1]\n",
      "  %const_starts__663[INT64, 1]\n",
      "  %const_starts__656[INT64, 1]\n",
      "  %const_starts__653[INT64, 1]\n",
      "  %const_fold_opt__1755[INT64, 2]\n",
      "  %const_ends__664[INT64, 1]\n",
      "  %const_ends__657[INT64, 1]\n",
      "  %const_ends__654[INT64, 1]\n",
      "  %const_empty_float__649[FLOAT, 0]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3cond_out__634 = Identity(%mask_rcnn_inference/roi_align_classifier/CropAndResize_3_cond__633)\n",
      "  %Add__642:0 = Add(%mask_rcnn_inference/roi_align_classifier/CropAndResize_3_i__632, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one_long__641)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_classifier/GatherNd_3:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_i__632, %Add__642:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero_long__639)\n",
      "  %Reshape__652:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_four__648)\n",
      "  %Slice__658:0 = Slice(%Reshape__652:0, %const_starts__656, %const_ends__657)\n",
      "  %Concat__660:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one_one__647, %Slice__658:0)\n",
      "  %Slice__655:0 = Slice(%Reshape__652:0, %const_starts__653, %const_ends__654)\n",
      "  %Concat__659:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero_zero__646, %Slice__655:0)\n",
      "  %Concat__661:0 = Concat[axis = 0](%Concat__659:0, %Concat__660:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Cast_4:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_i__632, %Add__642:0)\n",
      "  %Add__644:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one__640)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p5/BiasAdd:0, %Slice_a:0, %Add__644:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero__638)\n",
      "  %Shape__662:0 = Shape(%Slice_b:0)\n",
      "  %Slice__665:0 = Slice(%Shape__662:0, %const_starts__663, %const_ends__664)\n",
      "  %Concat__667:0 = Concat[axis = 0](%Slice__665:0, %const_fold_opt__1755)\n",
      "  %Resize__668:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__661:0, %const_empty_float__649, %Concat__667:0)\n",
      "  %Transpose__669:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__668:0)\n",
      "  %Squeeze__670:0 = Squeeze[axes = [0]](%Transpose__669:0)\n",
      "  return %mask_rcnn_inference/roi_align_classifier/CropAndResize_3cond_out__634, %Squeeze__670:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__681 (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_i__678[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_cond__679[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero_zero__692[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero_long__685[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero__684[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one_one__693[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one_long__687[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one__686[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_four__694[INT64, 1]\n",
      "  %const_starts__709[INT64, 1]\n",
      "  %const_starts__702[INT64, 1]\n",
      "  %const_starts__699[INT64, 1]\n",
      "  %const_fold_opt__1756[INT64, 2]\n",
      "  %const_ends__710[INT64, 1]\n",
      "  %const_ends__703[INT64, 1]\n",
      "  %const_ends__700[INT64, 1]\n",
      "  %const_empty_float__695[FLOAT, 0]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2cond_out__680 = Identity(%mask_rcnn_inference/roi_align_classifier/CropAndResize_2_cond__679)\n",
      "  %Add__688:0 = Add(%mask_rcnn_inference/roi_align_classifier/CropAndResize_2_i__678, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one_long__687)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_classifier/GatherNd_2:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_i__678, %Add__688:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero_long__685)\n",
      "  %Reshape__698:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_four__694)\n",
      "  %Slice__704:0 = Slice(%Reshape__698:0, %const_starts__702, %const_ends__703)\n",
      "  %Concat__706:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one_one__693, %Slice__704:0)\n",
      "  %Slice__701:0 = Slice(%Reshape__698:0, %const_starts__699, %const_ends__700)\n",
      "  %Concat__705:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero_zero__692, %Slice__701:0)\n",
      "  %Concat__707:0 = Concat[axis = 0](%Concat__705:0, %Concat__706:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Cast_3:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_i__678, %Add__688:0)\n",
      "  %Add__690:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one__686)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p4/BiasAdd:0, %Slice_a:0, %Add__690:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero__684)\n",
      "  %Shape__708:0 = Shape(%Slice_b:0)\n",
      "  %Slice__711:0 = Slice(%Shape__708:0, %const_starts__709, %const_ends__710)\n",
      "  %Concat__713:0 = Concat[axis = 0](%Slice__711:0, %const_fold_opt__1756)\n",
      "  %Resize__714:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__707:0, %const_empty_float__695, %Concat__713:0)\n",
      "  %Transpose__715:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__714:0)\n",
      "  %Squeeze__716:0 = Squeeze[axes = [0]](%Transpose__715:0)\n",
      "  return %mask_rcnn_inference/roi_align_classifier/CropAndResize_2cond_out__680, %Squeeze__716:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__727 (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_i__724[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_cond__725[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero_zero__738[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero_long__731[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero__730[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one_one__739[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one_long__733[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one__732[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_four__740[INT64, 1]\n",
      "  %const_starts__755[INT64, 1]\n",
      "  %const_starts__748[INT64, 1]\n",
      "  %const_starts__745[INT64, 1]\n",
      "  %const_fold_opt__1757[INT64, 2]\n",
      "  %const_ends__756[INT64, 1]\n",
      "  %const_ends__749[INT64, 1]\n",
      "  %const_ends__746[INT64, 1]\n",
      "  %const_empty_float__741[FLOAT, 0]\n",
      "  %Const__1577[INT64, 4]\n",
      "  %Const__1574[INT64, 4]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1cond_out__726 = Identity(%mask_rcnn_inference/roi_align_classifier/CropAndResize_1_cond__725)\n",
      "  %Add__734:0 = Add(%mask_rcnn_inference/roi_align_classifier/CropAndResize_1_i__724, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one_long__733)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_classifier/GatherNd_1:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_i__724, %Add__734:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero_long__731)\n",
      "  %Reshape__744:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_four__740)\n",
      "  %Slice__750:0 = Slice(%Reshape__744:0, %const_starts__748, %const_ends__749)\n",
      "  %Concat__752:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one_one__739, %Slice__750:0)\n",
      "  %Slice__747:0 = Slice(%Reshape__744:0, %const_starts__745, %const_ends__746)\n",
      "  %Concat__751:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero_zero__738, %Slice__747:0)\n",
      "  %Concat__753:0 = Concat[axis = 0](%Concat__751:0, %Concat__752:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Cast_2:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_i__724, %Add__734:0)\n",
      "  %Add__736:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one__732)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p3/BiasAdd:0, %Slice_a:0, %Add__736:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero__730)\n",
      "  %Shape__1576:0 = Shape(%Slice_b:0)\n",
      "  %Shape__1573:0 = Gather(%Shape__1576:0, %Const__1577)\n",
      "  %Shape__754:0 = Gather(%Shape__1573:0, %Const__1574)\n",
      "  %Slice__757:0 = Slice(%Shape__754:0, %const_starts__755, %const_ends__756)\n",
      "  %Concat__759:0 = Concat[axis = 0](%Slice__757:0, %const_fold_opt__1757)\n",
      "  %Resize__760:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__753:0, %const_empty_float__741, %Concat__759:0)\n",
      "  %Transpose__761:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__760:0)\n",
      "  %Squeeze__762:0 = Squeeze[axes = [0]](%Transpose__761:0)\n",
      "  return %mask_rcnn_inference/roi_align_classifier/CropAndResize_1cond_out__726, %Squeeze__762:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__773 (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_i__770[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_cond__771[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero_zero__784[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero_long__777[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero__776[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one_one__785[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one_long__779[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one__778[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_four__786[INT64, 1]\n",
      "  %const_starts__801[INT64, 1]\n",
      "  %const_starts__794[INT64, 1]\n",
      "  %const_starts__791[INT64, 1]\n",
      "  %const_fold_opt__1762[INT64, 2]\n",
      "  %const_ends__802[INT64, 1]\n",
      "  %const_ends__795[INT64, 1]\n",
      "  %const_ends__792[INT64, 1]\n",
      "  %const_empty_float__787[FLOAT, 0]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResizecond_out__772 = Identity(%mask_rcnn_inference/roi_align_classifier/CropAndResize_cond__771)\n",
      "  %Add__780:0 = Add(%mask_rcnn_inference/roi_align_classifier/CropAndResize_i__770, %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one_long__779)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_classifier/GatherNd:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_i__770, %Add__780:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero_long__777)\n",
      "  %Reshape__790:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_four__786)\n",
      "  %Slice__796:0 = Slice(%Reshape__790:0, %const_starts__794, %const_ends__795)\n",
      "  %Concat__798:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one_one__785, %Slice__796:0)\n",
      "  %Slice__793:0 = Slice(%Reshape__790:0, %const_starts__791, %const_ends__792)\n",
      "  %Concat__797:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero_zero__784, %Slice__793:0)\n",
      "  %Concat__799:0 = Concat[axis = 0](%Concat__797:0, %Concat__798:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Cast_1:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_i__770, %Add__780:0)\n",
      "  %Add__782:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one__778)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p2/BiasAdd:0, %Slice_a:0, %Add__782:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero__776)\n",
      "  %Shape__800:0 = Shape(%Slice_b:0)\n",
      "  %Slice__803:0 = Slice(%Shape__800:0, %const_starts__801, %const_ends__802)\n",
      "  %Concat__805:0 = Concat[axis = 0](%Slice__803:0, %const_fold_opt__1762)\n",
      "  %Resize__806:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__799:0, %const_empty_float__787, %Concat__805:0)\n",
      "  %Transpose__807:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__806:0)\n",
      "  %Squeeze__808:0 = Squeeze[axes = [0]](%Transpose__807:0)\n",
      "  return %mask_rcnn_inference/roi_align_classifier/CropAndResizecond_out__772, %Squeeze__808:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__1267 (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_i__1264[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_cond__1265[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero_zero__1278[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero_long__1271[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero__1270[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one_one__1279[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one_long__1273[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one__1272[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_four__1280[INT64, 1]\n",
      "  %const_starts__1294[INT64, 1]\n",
      "  %const_starts__1287[INT64, 1]\n",
      "  %const_starts__1284[INT64, 1]\n",
      "  %const_fold_opt__1758[INT64, 2]\n",
      "  %const_ends__1295[INT64, 1]\n",
      "  %const_ends__1288[INT64, 1]\n",
      "  %const_ends__1285[INT64, 1]\n",
      "  %const_empty_float__1281[FLOAT, 0]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3cond_out__1266 = Identity(%mask_rcnn_inference/roi_align_mask/CropAndResize_3_cond__1265)\n",
      "  %Add__1274:0 = Add(%mask_rcnn_inference/roi_align_mask/CropAndResize_3_i__1264, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one_long__1273)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_mask/GatherNd_3:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_i__1264, %Add__1274:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero_long__1271)\n",
      "  %Reshape__1283:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_four__1280)\n",
      "  %Slice__1289:0 = Slice(%Reshape__1283:0, %const_starts__1287, %const_ends__1288)\n",
      "  %Concat__1291:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one_one__1279, %Slice__1289:0)\n",
      "  %Slice__1286:0 = Slice(%Reshape__1283:0, %const_starts__1284, %const_ends__1285)\n",
      "  %Concat__1290:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero_zero__1278, %Slice__1286:0)\n",
      "  %Concat__1292:0 = Concat[axis = 0](%Concat__1290:0, %Concat__1291:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_mask/Cast_4:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_i__1264, %Add__1274:0)\n",
      "  %Add__1276:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one__1272)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p5/BiasAdd:0, %Slice_a:0, %Add__1276:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero__1270)\n",
      "  %Shape__1293:0 = Shape(%Slice_b:0)\n",
      "  %Slice__1296:0 = Slice(%Shape__1293:0, %const_starts__1294, %const_ends__1295)\n",
      "  %Concat__1298:0 = Concat[axis = 0](%Slice__1296:0, %const_fold_opt__1758)\n",
      "  %Resize__1299:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__1292:0, %const_empty_float__1281, %Concat__1298:0)\n",
      "  %Transpose__1300:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__1299:0)\n",
      "  %Squeeze__1301:0 = Squeeze[axes = [0]](%Transpose__1300:0)\n",
      "  return %mask_rcnn_inference/roi_align_mask/CropAndResize_3cond_out__1266, %Squeeze__1301:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__1312 (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_i__1309[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_cond__1310[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero_zero__1323[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero_long__1316[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero__1315[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one_one__1324[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one_long__1318[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one__1317[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_four__1325[INT64, 1]\n",
      "  %const_starts__1339[INT64, 1]\n",
      "  %const_starts__1332[INT64, 1]\n",
      "  %const_starts__1329[INT64, 1]\n",
      "  %const_fold_opt__1759[INT64, 2]\n",
      "  %const_ends__1340[INT64, 1]\n",
      "  %const_ends__1333[INT64, 1]\n",
      "  %const_ends__1330[INT64, 1]\n",
      "  %const_empty_float__1326[FLOAT, 0]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2cond_out__1311 = Identity(%mask_rcnn_inference/roi_align_mask/CropAndResize_2_cond__1310)\n",
      "  %Add__1319:0 = Add(%mask_rcnn_inference/roi_align_mask/CropAndResize_2_i__1309, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one_long__1318)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_mask/GatherNd_2:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_i__1309, %Add__1319:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero_long__1316)\n",
      "  %Reshape__1328:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_four__1325)\n",
      "  %Slice__1334:0 = Slice(%Reshape__1328:0, %const_starts__1332, %const_ends__1333)\n",
      "  %Concat__1336:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one_one__1324, %Slice__1334:0)\n",
      "  %Slice__1331:0 = Slice(%Reshape__1328:0, %const_starts__1329, %const_ends__1330)\n",
      "  %Concat__1335:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero_zero__1323, %Slice__1331:0)\n",
      "  %Concat__1337:0 = Concat[axis = 0](%Concat__1335:0, %Concat__1336:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_mask/Cast_3:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_i__1309, %Add__1319:0)\n",
      "  %Add__1321:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one__1317)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p4/BiasAdd:0, %Slice_a:0, %Add__1321:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero__1315)\n",
      "  %Shape__1338:0 = Shape(%Slice_b:0)\n",
      "  %Slice__1341:0 = Slice(%Shape__1338:0, %const_starts__1339, %const_ends__1340)\n",
      "  %Concat__1343:0 = Concat[axis = 0](%Slice__1341:0, %const_fold_opt__1759)\n",
      "  %Resize__1344:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__1337:0, %const_empty_float__1326, %Concat__1343:0)\n",
      "  %Transpose__1345:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__1344:0)\n",
      "  %Squeeze__1346:0 = Squeeze[axes = [0]](%Transpose__1345:0)\n",
      "  return %mask_rcnn_inference/roi_align_mask/CropAndResize_2cond_out__1311, %Squeeze__1346:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__1357 (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_i__1354[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_cond__1355[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero_zero__1368[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero_long__1361[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero__1360[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one_one__1369[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one_long__1363[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one__1362[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_four__1370[INT64, 1]\n",
      "  %const_starts__1384[INT64, 1]\n",
      "  %const_starts__1377[INT64, 1]\n",
      "  %const_starts__1374[INT64, 1]\n",
      "  %const_fold_opt__1761[INT64, 2]\n",
      "  %const_ends__1385[INT64, 1]\n",
      "  %const_ends__1378[INT64, 1]\n",
      "  %const_ends__1375[INT64, 1]\n",
      "  %const_empty_float__1371[FLOAT, 0]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1cond_out__1356 = Identity(%mask_rcnn_inference/roi_align_mask/CropAndResize_1_cond__1355)\n",
      "  %Add__1364:0 = Add(%mask_rcnn_inference/roi_align_mask/CropAndResize_1_i__1354, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one_long__1363)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_mask/GatherNd_1:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_i__1354, %Add__1364:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero_long__1361)\n",
      "  %Reshape__1373:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_four__1370)\n",
      "  %Slice__1379:0 = Slice(%Reshape__1373:0, %const_starts__1377, %const_ends__1378)\n",
      "  %Concat__1381:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one_one__1369, %Slice__1379:0)\n",
      "  %Slice__1376:0 = Slice(%Reshape__1373:0, %const_starts__1374, %const_ends__1375)\n",
      "  %Concat__1380:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero_zero__1368, %Slice__1376:0)\n",
      "  %Concat__1382:0 = Concat[axis = 0](%Concat__1380:0, %Concat__1381:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_mask/Cast_2:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_i__1354, %Add__1364:0)\n",
      "  %Add__1366:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one__1362)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p3/BiasAdd:0, %Slice_a:0, %Add__1366:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero__1360)\n",
      "  %Shape__1383:0 = Shape(%Slice_b:0)\n",
      "  %Slice__1386:0 = Slice(%Shape__1383:0, %const_starts__1384, %const_ends__1385)\n",
      "  %Concat__1388:0 = Concat[axis = 0](%Slice__1386:0, %const_fold_opt__1761)\n",
      "  %Resize__1389:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__1382:0, %const_empty_float__1371, %Concat__1388:0)\n",
      "  %Transpose__1390:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__1389:0)\n",
      "  %Squeeze__1391:0 = Squeeze[axes = [0]](%Transpose__1390:0)\n",
      "  return %mask_rcnn_inference/roi_align_mask/CropAndResize_1cond_out__1356, %Squeeze__1391:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__1402 (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_i__1399[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_cond__1400[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero_zero__1413[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero_long__1406[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero__1405[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_one_one__1414[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_one_long__1408[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_one__1407[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_four__1415[INT64, 1]\n",
      "  %const_starts__1429[INT64, 1]\n",
      "  %const_starts__1422[INT64, 1]\n",
      "  %const_starts__1419[INT64, 1]\n",
      "  %const_fold_opt__1760[INT64, 2]\n",
      "  %const_ends__1430[INT64, 1]\n",
      "  %const_ends__1423[INT64, 1]\n",
      "  %const_ends__1420[INT64, 1]\n",
      "  %const_empty_float__1416[FLOAT, 0]\n",
      "  %Const__1587[INT64, 4]\n",
      "  %Const__1584[INT64, 4]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResizecond_out__1401 = Identity(%mask_rcnn_inference/roi_align_mask/CropAndResize_cond__1400)\n",
      "  %Add__1409:0 = Add(%mask_rcnn_inference/roi_align_mask/CropAndResize_i__1399, %mask_rcnn_inference/roi_align_mask/CropAndResize_const_one_long__1408)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_mask/GatherNd:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_i__1399, %Add__1409:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero_long__1406)\n",
      "  %Reshape__1418:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_const_four__1415)\n",
      "  %Slice__1424:0 = Slice(%Reshape__1418:0, %const_starts__1422, %const_ends__1423)\n",
      "  %Concat__1426:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_const_one_one__1414, %Slice__1424:0)\n",
      "  %Slice__1421:0 = Slice(%Reshape__1418:0, %const_starts__1419, %const_ends__1420)\n",
      "  %Concat__1425:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero_zero__1413, %Slice__1421:0)\n",
      "  %Concat__1427:0 = Concat[axis = 0](%Concat__1425:0, %Concat__1426:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_mask/Cast_1:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_i__1399, %Add__1409:0)\n",
      "  %Add__1411:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_const_one__1407)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p2/BiasAdd:0, %Slice_a:0, %Add__1411:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero__1405)\n",
      "  %Shape__1586:0 = Shape(%Slice_b:0)\n",
      "  %Shape__1583:0 = Gather(%Shape__1586:0, %Const__1587)\n",
      "  %Shape__1428:0 = Gather(%Shape__1583:0, %Const__1584)\n",
      "  %Slice__1431:0 = Slice(%Shape__1428:0, %const_starts__1429, %const_ends__1430)\n",
      "  %Concat__1433:0 = Concat[axis = 0](%Slice__1431:0, %const_fold_opt__1760)\n",
      "  %Resize__1434:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__1427:0, %const_empty_float__1416, %Concat__1433:0)\n",
      "  %Transpose__1435:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__1434:0)\n",
      "  %Squeeze__1436:0 = Squeeze[axes = [0]](%Transpose__1435:0)\n",
      "  return %mask_rcnn_inference/roi_align_mask/CropAndResizecond_out__1401, %Squeeze__1436:0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load the ONNX model\n",
    "model = onnx.load(f'../weights/{model_name}.onnx')\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model for TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial graph inputs: [Variable (input_image): (shape=[1, 512, 512, 3], dtype=float32), Variable (input_image_meta): (shape=[1, 14], dtype=float32)]\n",
      "\n",
      "Initial graph outputs: [Variable (mrcnn_detection): (shape=[1, 100, 6], dtype=float32), Variable (fpnclf_mrcnn_class): (shape=['unk__2801', 1000, 2], dtype=float32), Variable (fpnclf_mrcnn_bbox_reshape): (shape=['unk__2802', 1000, 2, 4], dtype=float32), Variable (mrcnn_mask): (shape=[1, 100, 28, 28, 2], dtype=float32), Variable (roi): (shape=[1, 'unk__2803', 'unk__2804'], dtype=float32), Variable (concat_rpn_class): (shape=[1, 65472, 2], dtype=float32), Variable (concat_rpn_bbox): (shape=[1, 65472, 4], dtype=float32)]\n",
      "Already cleared: mask_rcnn_inference/mrcnn_detection/Unique:1\n",
      "Already cleared: mask_rcnn_inference/mrcnn_detection/Unique:2\n",
      "Already cleared: mask_rcnn_inference/mrcnn_detection/TopKV2:0\n",
      "Already cleared: mask_rcnn_inference/roi/top_anchors:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/Unique:1\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/Unique:2\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/TopKV2:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/GatherNd_3:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/GatherNd_2:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/GatherNd_1:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/GatherNd:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/Unique:1\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/Unique:2\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/TopKV2:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/GatherNd_3:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/GatherNd_2:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/GatherNd_1:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/GatherNd:0\n",
      "\n",
      "ResizeNearest_TRT attributes: {'scale': 2.0}\n",
      "Resize__303:0\n",
      "Resize__313:0\n",
      "Resize__323:0\n",
      "\n",
      "ProposalLayer_TRT attributes: {'prenms_topk': 1024, 'keep_topk': 1000, 'iou_threshold': 0.7, 'image_size': (3, 512, 512)}\n",
      "\n",
      "PyramidROIAlign_TRT attributes: {'pooled_size': 7}\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv1/Reshape\n",
      "Nodes:  [386]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv1/Shape\n",
      "Nodes:  [381]\n",
      "\n",
      "DetectionLayer_TRT attributes: {'num_classes': 2, 'keep_topk': 100, 'score_threshold': 0.7, 'iou_threshold': 0.3}\n",
      "\n",
      "Added SpecialSlice_TRT\n",
      "\n",
      "PyramidROIAlign_TRT attributes: {'pooled_size': 14}\n",
      "Node name:  mask_rcnn_inference/mrcnn_mask_conv1/Reshape\n",
      "Nodes:  [696]\n",
      "Node name:  mask_rcnn_inference/fpnclf_mrcnn_bbox_reshape/Reshape\n",
      "Nodes:  [459]\n",
      "Removed node: mask_rcnn_inference/fpnclf_mrcnn_class/Reshape_1 (Reshape)\n",
      "\tInputs: []\n",
      "\tOutputs: []\n",
      "Node name:  mask_rcnn_inference/backbone_mobilenet/conv_pad_2/Pad\n",
      "Nodes:  [29]\n",
      "Node name:  mask_rcnn_inference/backbone_mobilenet/conv_pad_4/Pad\n",
      "Nodes:  [39]\n",
      "Node name:  mask_rcnn_inference/backbone_mobilenet/conv_pad_6/Pad\n",
      "Nodes:  [49]\n",
      "Node name:  mask_rcnn_inference/backbone_mobilenet/conv_pad_12/Pad\n",
      "Nodes:  [75]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv1/Shape\n",
      "Nodes:  [381]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv1/Reshape_1\n",
      "Nodes:  [389]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn1/Reshape\n",
      "Nodes:  [395]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn1/Reshape_1\n",
      "Nodes:  [398]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv2/Shape\n",
      "Nodes:  [402]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv2/Reshape_1\n",
      "Nodes:  [407]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn2/Reshape\n",
      "Nodes:  [413]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn2/Reshape_1\n",
      "Nodes:  [416]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3__852\n",
      "Nodes:  [396]\n",
      "Node name:  mask_rcnn_inference/fpnclf_relu_act1/Relu\n",
      "Nodes:  [399]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd__869\n",
      "Nodes:  [400]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/FusedBatchNormV3__886\n",
      "Nodes:  [414]\n",
      "Node name:  mask_rcnn_inference/fpnclf_relu_act2/Relu\n",
      "Nodes:  [417]\n",
      "\n",
      "Modified graph inputs: [Variable (input_image): (shape=[1, 512, 512, 3], dtype=float32)]\n",
      "\n",
      "Modified graph outputs: [Variable (mrcnn_detection): (shape=(1, 100, 6), dtype=<class 'numpy.float32'>), Variable (mrcnn_mask): (shape=[1, 100, 28, 28, 2], dtype=float32)]\n",
      "\n",
      "Model ../weights/maskrcnn_mobilenet_512_512_3.onnx  was successfully modified for TensorRT optimization: ../weights/maskrcnn_mobilenet_512_512_3_trt_mod.onnx\n"
     ]
    }
   ],
   "source": [
    "modify_onnx_model(model_path=f'../weights/{model_name}.onnx',\n",
    "                  config=CONFIG,\n",
    "                  verbose=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorRT optimization\n",
    "\n",
    "__With trtexec:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexander/TensorRT-7.2.3.4/bin/trtexec'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TRTEXEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arch: x86_64\n",
      "trtexec command list: ['/home/alexander/TensorRT-7.2.3.4/bin/trtexec', '--onnx=maskrcnn_mobilenet_512_512_3_trt_mod.onnx', '--saveEngine=maskrcnn_mobilenet_512_512_3_trt_mod_fp32.engine', '--workspace=2048', '--explicitBatch', '--verbose', '--tacticSources=-cublasLt,+cublas']\n",
      "016\n",
      "[06/24/2021-02:14:17] [V] [TRT] Allocated activation device memory of size 329411584\n",
      "[06/24/2021-02:14:17] [V] [TRT] Assigning persistent memory blocks for various profiles\n",
      "[06/24/2021-02:14:17] [I] Starting inference\n",
      "[06/24/2021-02:14:20] [I] Warmup completed 0 queries over 200 ms\n",
      "[06/24/2021-02:14:20] [I] Timing trace has 0 queries over 3.13159 s\n",
      "[06/24/2021-02:14:20] [I] Trace averages of 10 runs:\n",
      "[06/24/2021-02:14:20] [I] Average on 10 runs - GPU latency: 51.1195 ms - Host latency: 51.5417 ms (end to end 103.045 ms, enqueue 2.57648 ms)\n",
      "[06/24/2021-02:14:20] [I] Average on 10 runs - GPU latency: 51.1507 ms - Host latency: 51.5731 ms (end to end 102.158 ms, enqueue 2.75852 ms)\n",
      "[06/24/2021-02:14:20] [I] Average on 10 runs - GPU latency: 51.037 ms - Host latency: 51.4665 ms (end to end 101.715 ms, enqueue 2.74753 ms)\n",
      "[06/24/2021-02:14:20] [I] Average on 10 runs - GPU latency: 51.3107 ms - Host latency: 51.7419 ms (end to end 102.18 ms, enqueue 2.92241 ms)\n",
      "[06/24/2021-02:14:20] [I] Average on 10 runs - GPU latency: 50.9897 ms - Host latency: 51.4179 ms (end to end 101.607 ms, enqueue 2.93577 ms)\n",
      "[06/24/2021-02:14:20] [I] Average on 10 runs - GPU latency: 51.2274 ms - Host latency: 51.6485 ms (end to end 102.311 ms, enqueue 2.51558 ms)\n",
      "[06/24/2021-02:14:20] [I] Host Latency\n",
      "[06/24/2021-02:14:20] [I] min: 50.4961 ms (end to end 101.065 ms)\n",
      "[06/24/2021-02:14:20] [I] max: 52.5894 ms (end to end 114.929 ms)\n",
      "[06/24/2021-02:14:20] [I] mean: 51.5649 ms (end to end 102.169 ms)\n",
      "[06/24/2021-02:14:20] [I] median: 51.7722 ms (end to end 101.92 ms)\n",
      "[06/24/2021-02:14:20] [I] percentile: 52.5894 ms at 99% (end to end 114.929 ms at 99%)\n",
      "[06/24/2021-02:14:20] [I] throughput: 0 qps\n",
      "[06/24/2021-02:14:20] [I] walltime: 3.13159 s\n",
      "[06/24/2021-02:14:20] [I] Enqueue Time\n",
      "[06/24/2021-02:14:20] [I] min: 0.815979 ms\n",
      "[06/24/2021-02:14:20] [I] max: 3.02515 ms\n",
      "[06/24/2021-02:14:20] [I] median: 2.92889 ms\n",
      "[06/24/2021-02:14:20] [I] GPU Compute\n",
      "[06/24/2021-02:14:20] [I] min: 50.0879 ms\n",
      "[06/24/2021-02:14:20] [I] max: 52.1706 ms\n",
      "[06/24/2021-02:14:20] [I] mean: 51.1392 ms\n",
      "[06/24/2021-02:14:20] [I] median: 51.342 ms\n",
      "[06/24/2021-02:14:20] [I] percentile: 52.1706 ms at 99%\n",
      "[06/24/2021-02:14:20] [I] total compute time: 3.06835 s\n",
      "&&&& PASSED TensorRT.trtexec # /home/alexander/TensorRT-7.2.3.4/bin/trtexec --onnx=maskrcnn_mobilenet_512_512_3_trt_mod.onnx --saveEngine=maskrcnn_mobilenet_512_512_3_trt_mod_fp32.engine --workspace=2048 --explicitBatch --verbose --tacticSources=-cublasLt,+cublas\n",
      "\n",
      "CPU times: user 4.25 s, sys: 2.22 s, total: 6.46 s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "os.chdir('../weights')\n",
    "\n",
    "# Construct appropriate command\n",
    "fp16_mode = False\n",
    "command = [os.environ['TRTEXEC'],\n",
    "           f'--onnx={model_name}_trt_mod.onnx',\n",
    "           f'--saveEngine={model_name}_trt_mod_fp32.engine',\n",
    "            '--workspace=2048',\n",
    "            '--explicitBatch',\n",
    "            '--verbose',\n",
    "          ]\n",
    "\n",
    "# fp16 param\n",
    "if fp16_mode:\n",
    "    command[2].replace('32', '16')\n",
    "    command.append('--fp16')\n",
    "\n",
    "# tacticSources param\n",
    "# Do not neeed on jetson with aarch64 architecture for now.\n",
    "arch = os.uname().machine\n",
    "if arch == 'x86_64':\n",
    "    command.append('--tacticSources=-cublasLt,+cublas')\n",
    "    \n",
    "print(f'\\nArch: {arch}\\ntrtexec command list: {command}')\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, check=True)\n",
    "# Print stdout inference result\n",
    "print(result.stdout.decode('utf8')[-2495:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__With python TensorRT API:__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_batch_size = 1\n",
    "# Precision mode\n",
    "fp16_mode = False\n",
    "# Workspace size in Mb\n",
    "wspace_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of detected layers:  233\n",
      "Detected inputs:  1\n",
      "Detected outputs:  2\n",
      "CPU times: user 17.8 s, sys: 3.05 s, total: 20.9 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Init TensorRT Logger\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE)\n",
    "# Init TensorRT plugins\n",
    "trt.init_libnvinfer_plugins(TRT_LOGGER, \"\")\n",
    "# Set tensorrt-prepared onnx model\n",
    "onnx_model_path = f'../weights/{model_name}_trt_mod.onnx'\n",
    "# Use explicit batch\n",
    "explicit_batch = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "        builder.create_builder_config() as builder_config, \\\n",
    "        builder.create_network(explicit_batch) as network, \\\n",
    "        trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "    with open(onnx_model_path, 'rb') as model:\n",
    "        parser.parse(model.read())\n",
    "\n",
    "    print('Num of detected layers: ', network.num_layers)\n",
    "    print('Detected inputs: ', network.num_inputs)\n",
    "    print('Detected outputs: ', network.num_outputs)\n",
    "    \n",
    "    # Workspace size\n",
    "    # 1e6 bytes == 1Mb\n",
    "    builder_config.max_workspace_size = int(1e6 * wspace_size)\n",
    "    \n",
    "    # Precision mode\n",
    "    if fp16_mode:\n",
    "        builder_config.set_flag(trt.BuilderFlag.FP16)\n",
    "    \n",
    "    # Max batch size\n",
    "    builder.max_batch_size = max_batch_size\n",
    "    \n",
    "    # Set the list of tactic sources\n",
    "    # Do not need for Jetson with aarch64 architecture for now\n",
    "    arch = os.uname().machine\n",
    "    if arch == 'x86_64':\n",
    "        tactic_source = 1 << int(trt.TacticSource.CUBLAS) | 0 << int(trt.TacticSource.CUBLAS_LT)\n",
    "        builder_config.set_tactic_sources(tactic_source)\n",
    "        \n",
    "    \n",
    "    # Make TensorRT engine\n",
    "    engine = builder.build_engine(network, builder_config)\n",
    "    \n",
    "    # Save TensorRT engine\n",
    "    if fp16_mode:\n",
    "        trt_model_name = f'../weights/{model_name}_fp16_trt.engine'\n",
    "    else:\n",
    "        trt_model_name = f'../weights/{model_name}_fp32_trt.engine'\n",
    "\n",
    "    with open(trt_model_name, \"wb\") as f:\n",
    "        f.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
